[{"content":"In this post, I have documented the steps I followed to install RHEL 8 by booting from a PXE server over the network with a Kickstart file using Synology NAS as TFTP, HTTP server, and UDM as DHCP.\n Install \u0026amp; Configure TFTP Install \u0026amp; Configure HTTP server Enable network boot on UDM PXE Boot setup  Prepare Installation Repository Prepare kickstart file Perform PXE boot    Install and Configure TFTP Trivial File Transfer Protocol (TFTP) is a simple file transfer protocol, generally used for transferring configurations or boot files when authentication is not required.\nSynology NAS comes with TFTP file services\nTo configure TFTP Go to Control Panel \u0026gt; File Services \u0026gt; Advanced\n Select Enable TFTP Service In the TFTP root folder field, specify which folder on the Synology NAS can be accessed by TFTP clients   TFTP \nInstall and Configure HTTP server We also need a service to host our image repository, we can use FTP or HTTP, or NFS to host our image repository. Synology NAS comes with web hosting features. In Web Station, we will create a port-based virtual host to host the contents of our image repository.\nInstall the following packages from the Synology package center\n Web Station Apache HTTP Server 2.4  Create a virtual host Open Web Station and go to Web Service Portal \u0026gt; Select Create Service Portal\n Create Service \nSelect Virtual Host\n Create Virtual Host \nIn the virtual host wizard\n Select Port-based with protocol as HTTP and enter port number 8080 Select the Document root directory which is the same PXE location as TFTP Select Apache HTTP Server as the back-end server Click Create to save settings   HTTP Port based host \nWe need to enable simple directory browsing on the virtual host we just create to access the contents of images and configuration files to perform PXE Boot.\nIn the Document root directory create a file named .htaccess with the following content\nOptions +Indexes Navigate to IP:8080 and you should see a similar screen with files in the folder\n HTTP Server \nPXE Boot setup Prepare Installation Repository  Download the ISO image file of the full installation DVD Create a directory named images/rhel/8.6 under root directory of TFTP/HTTP server Mount the ISO image Copy all the files from the ISO to the previously created directory on TFTP/HTTP server. You will need around 10GB of storage to copy all the files from the ISO to the local directory.  mount rhel-8.6-x86_64-dvd.iso /mnt scp -pr /mnt/* nas-user@nas-address:/media/PXE/images/rhel/8.6 To perform UEFI PXE Boot installation, we will need the following PXE boot files\n grubx64.efi provided by grub2-efi-x64 rpm shimx64.efi provided by shim-x64 rpm BOOTX64.EFI provided by shim-x64 rpm  cp -pr /mnt/BaseOS/Packages/grub2-efi-x64-2.02-81.el8.x86_64.rpm /tmp cp -pr /mnt/BaseOS/Packages/shim-x64-15-11.el8.x86_64.rpm /tmp/ Extract the packages\ncd /tmp rpm2cpio shim-x64-15-11.el8.x86_64.rpm | cpio -dimv rpm2cpio grub2-efi-x64-2.02-81.el8.x86_64.rpm | cpio -dimv Copy the EFI boot images from the /tmp directory to the PXE root directory\nscp /tmp/boot/efi/EFI/BOOT/BOOTX64.EFI nas-user@nas-address:/media/PXE scp /tmp/boot/efi/EFI/centos/shimx64.efi nas-user@nas-address:/media/PXE scp /tmp/boot/efi/EFI/centos/grubx64.efi nas-user@nas-address:/media/PXE Add a configuration file named grub.cfg to the TFTP/HTTP root directory. We need initrd and vmlinuz files to load the Operating System until the hard disk and other interfaces are detected. In the grub.cfg take a note of linuxefi and initrdefi I am referring to TFTP/HTTP image directory location.\nset timeout=30 menuentry \u0026#39;Install RHEL 8.6 on T7910\u0026#39; { linuxefi images/rhel/8.6/images/pxeboot/vmlinuz inst.stage2=http://192.168.100.160:8080/images/rhel/8.6 quiet initrdefi images/rhel/8.6/images/pxeboot/initrd.img } Prepare kickstart file Next, we will create our kickstart file to have an unattended automated installation. I have used the Kickstart Configuration Tool available at https://access.redhat.com/labs/kickstartconfig/ in the Red Hat Customer Portal Labs. This tool will walk you through basic configuration and allows you to download the resulting Kickstart file.\n Create a new directory named ks under the root directory of TFTP/HTTP server to store the kickstart file for the UEFI PXE Boot purpose Copy the downloaded kickstart file into the previously created location  scp kickstart.cfg nas-user@nas-address:/media/PXE/ks  Update the grub.cfg to use the kickstart file during installation. The inst.ks= boot option specifies the location of the kickstart location  The final grub.cfg will look like this:\nset timeout=30 menuentry \u0026#39;Install RHEL 8.6 on T7910\u0026#39; { linuxefi images/rhel/8.6/images/pxeboot/vmlinuz inst.ks=http://192.168.100.160:8080/ks/rhel8-t7910.cfg inst.stage2=http://192.168.100.160:8080/images/rhel/8.6 quiet initrdefi images/rhel/8.6/images/pxeboot/initrd.img } Perform PXE boot We are all set up to perform UEFI PXE Boot. The shortcut button to boot over the network may vary for different hardware but in most cases we are expected to press F12 to boot from the network:\nIf your UEFI PXE Boot Server configuration is proper, then the TFTP files should get successfully\n","date":"2022-05-13T16:09:15-05:00","permalink":"https://vikaspogu.github.io/posts/tftp-udm-pxe/","title":"PXE boot with Synology NAS and UDM router"},{"content":"Recently I was in a situation where I ended up writing multiple if-else statements in the helm template. Code block didn\u0026rsquo;t look clean and, I begin to explore alternative ways to achieve a clean and concise way to achieve the same behavior.\nHelm dict function perfectly fits my use case.\nBefore\n{{- if eq .Values.imageType \u0026#34;java\u0026#34; }}name:openjdk:latest{{- else if eq .Values.imageType \u0026#34;nodejs\u0026#34; }}name:nodejs:latest{{- else if eq .Values.imageType \u0026#34;golang\u0026#34; }}name:golang:latest{{- else if eq .Values.imageType \u0026#34;python\u0026#34; }}name:python:latest{{- end }}After\n{{- $imageTypes := dict }}{{- $_ := set $imageTypes \u0026#34;java\u0026#34; \u0026#34;openjdk:latest\u0026#34; }}{{- $_ := set $imageTypes \u0026#34;nodejs\u0026#34; \u0026#34;nodejs:latest\u0026#34; }}{{- $_ := set $imageTypes \u0026#34;python\u0026#34; \u0026#34;openjdk:latest\u0026#34; }}{{- $_ := set $imageTypes \u0026#34;java\u0026#34; \u0026#34;openjdk:latest\u0026#34; }}...name:{{get $imageTypes .Values.imageType }}","date":"2021-07-08T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/helm-dict-function/","title":"Helm alternative for multiple If-Else conditions"},{"content":"There are three different strategies to build multi-platform images that are supported by Buildx and Dockerfiles:\n Using the QEMU emulation support in the kernel Building on multiple native nodes using the same builder instance Using a stage in Dockerfile to cross-compile to different architectures  I’ll focus on the first option, cross building with emulation.\ndocker buildx build --platform linux/amd64,linux/arm64 . Setup This differs from platform to platform but one thing we all have in common is pipelines, so I’ve constructed a basic buildx setup for TektonCD task.\nPipeline Below is a modified task of docker-build\nWhat\u0026rsquo;s modified\n Enable DOCKER_BUILDKIT and DOCKER_CLI_EXPERIMENTAL Install docker-buildx plugin Run the latest docker/binfmt tag to use its qemu parts Docker login (using secret for values) Docker build with docker buildx build --platform  Create a secret holding docker username and token\nkubectl create secret generic docker-token \\  --from-literal=username=\u0026#34;${CONTAINER_REGISTRY_USER}\u0026#34; \\  --from-literal=password=\u0026#34;${CONTAINER_REGISTRY_PASSWORD}\u0026#34; apiVersion:tekton.dev/v1beta1kind:ClusterTaskmetadata:name:docker-buildxlabels:app.kubernetes.io/version:\u0026#34;0.1\u0026#34;annotations:tekton.dev/pipelines.minVersion:\u0026#34;0.12.1\u0026#34;tekton.dev/tags:docker, build-image, push-image, dind, buildx, multi-archtekton.dev/displayName:docker-buildxspec:description:\u0026gt;-This task will build and push an image using docker buildx. The task will build an out image out of a Dockerfile. This image will be pushed to an image registry. The image will be built and pushed using a dind sidecar over TCP+TLS.params:- name:imagedescription:Reference of the image docker will produce.- name:builder_imagedescription:The location of the docker builder image.default:docker.io/library/docker:19.03.14- name:dockerfiledescription:Path to the Dockerfile to build.default:./Dockerfile- name:contextdescription:Path to the directory to use as context.default:.- name:build_extra_argsdescription:Extra parameters passed for the build command when building images.default:\u0026#34;--platform linux/amd64,linux/arm/v7 --no-cache\u0026#34;- name:push_extra_argsdescription:Extra parameters passed for the push command when pushing images.default:\u0026#34;--push\u0026#34;- name:insecure_registrydescription:Allows the user to push to an insecure registry that has been specifieddefault:\u0026#34;\u0026#34;- name:docker-token-secrettype:stringdescription:name of the secret holding the docker-tokendefault:docker-tokenworkspaces:- name:sourceresults:- name:IMAGE_DIGESTdescription:Digest of the image just built.steps:- name:buildx-build-pushimage:$(params.builder_image)env:# Connect to the sidecar over TCP, with TLS.- name:DOCKER_HOSTvalue:tcp://localhost:2376# Verify TLS.- name:DOCKER_TLS_VERIFYvalue:\u0026#39;1\u0026#39;# Use the certs generated by the sidecar daemon.- name:DOCKER_CERT_PATHvalue:/certs/client- name:DOCKERHUB_USERvalueFrom:secretKeyRef:name:$(params.docker-token-secret)key:username- name:DOCKERHUB_PASSvalueFrom:secretKeyRef:name:$(params.docker-token-secret)key:passwordworkingDir:$(workspaces.source.path)script:|# install depends apk add curl jq # enable experimental buildx features export DOCKER_BUILDKIT=1 export DOCKER_CLI_EXPERIMENTAL=enabled # Download latest buildx bin from github mkdir -p ~/.docker/cli-plugins/ BUILDX_LATEST_BIN_URI=$(curl -s -L https://github.com/docker/buildx/releases/latest | grep \u0026#39;linux-amd64\u0026#39; | grep \u0026#39;href\u0026#39; | sed \u0026#39;s/.*href=\u0026#34;/https:\\/\\/github.com/g; s/amd64\u0026#34;.*/amd64/g\u0026#39;) curl -s -L ${BUILDX_LATEST_BIN_URI} -o ~/.docker/cli-plugins/docker-buildx chmod a+x ~/.docker/cli-plugins/docker-buildx # Get and run the latest docker/binfmt tag to use its qemu parts BINFMT_IMAGE_TAG=$(curl -s https://registry.hub.docker.com/v2/repositories/docker/binfmt/tags | jq \u0026#39;.results | sort_by(.last_updated)[-1].name\u0026#39; -r) docker run --rm --privileged docker/binfmt:${BINFMT_IMAGE_TAG} docker context create tls-environment # create the multibuilder docker buildx create --name multibuilder --use tls-environment docker buildx use multibuilder # login to a registry echo ${DOCKERHUB_PASS} | docker login -u ${DOCKERHUB_USER} --password-stdin # build the containers and push them to the registry then display the images docker buildx build $(params.build_extra_args) \\ -f $(params.dockerfile) -t $(params.image) $(params.context) $(params.push_extra_args)volumeMounts:- mountPath:/certs/clientname:dind-certssidecars:- image:docker:19.03.14-dindname:serverargs:- --storage-driver=vfs- --userland-proxy=false- --debugsecurityContext:privileged:trueenv:# Write generated certs to the path shared with the client.- name:DOCKER_TLS_CERTDIRvalue:/certsvolumeMounts:- mountPath:/certs/clientname:dind-certs# Wait for the dind daemon to generate the certs it will share with the# client.readinessProbe:periodSeconds:1exec:command:[\u0026#39;ls\u0026#39;,\u0026#39;/certs/client/ca.pem\u0026#39;]volumes:- name:dind-certsemptyDir:{}Make sure you have a base image that supports multiarch like alpine or one of these base images\n","date":"2021-01-19T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/tekton-multiarch-buildx/","title":"Build multi arch docker image using Tekton"},{"content":"Tekton Triggers work by having EventListeners receive incoming webhook notifications, processing them using an Interceptor, and creating Kubernetes resources from templates if the interceptor allows it, with extraction of fields from the body of the webhook\nCEL Interceptors can be used to filter or modify incoming events. for example if you want to truncate commit id from the webhook body\napiVersion:triggers.tekton.dev/v1alpha1kind:EventListenermetadata:name:shared-listenernamespace:defaultspec:serviceAccountName:build-bottriggers:- name:shared-pipeline-triggerinterceptors:- cel:overlays:- key:intercepted.commit_id_shortexpression:\u0026#34;body.head_commit.id.truncate(7)\u0026#34;bindings:- ref:pipeline-bindingtemplate:ref:pipeline-templateApplied overlay can be extracted using a extensions body in the binding. In below example $(extensions.\u0026lt;overlay_key\u0026gt;)\napiVersion:triggers.tekton.dev/v1alpha1kind:TriggerBindingmetadata:name:pipeline-bindingnamespace:defaultspec:params:- name:git-repo-namevalue:$(body.repository.name)- name:git-repo-urlvalue:$(body.repository.url)- name:image-tagvalue:$(extensions.intercepted.commit_id_short)","date":"2021-01-19T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/tekton-triggers-cel-interception/","title":"Tekton triggers and Interceptors"},{"content":"In this post, I will:\n Use Tekton to build and publish image to docker registry Trigger a Tekton pipeline from GitHub Use Argo to deploy application   alt argo-flow-1 \nGetting Started Assumptions:\n You have a running OpenShift 4 cluster with ArgoCD, and OpenShift Pipelines installed. If not, you follow instructions to OpenShift Pipelines and ArgoCD Operator Understand of basic argocd and tekton concepts  Create an OpenShift project called node-web-project\noc new-project node-web-project Using Private Registries Create a docker secret with registry authentication details\noc create secret docker-registry container-registry-secret \\  --docker-server=$CONTAINER_REGISTRY_SERVER \\  --docker-username=$CONTAINER_REGISTRY_USER \\  --docker-password=$CONTAINER_REGISTRY_PASSWORD -n node-web-project Create a service account named build-bot\noc create sa -n node-web-project build-bot serviceaccount/build-bot created Add docker secret container-registry-secret to newly created service account build-bot\noc patch serviceaccount build-bot \\  -p \u0026#39;{\u0026#34;secrets\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;container-registry-secret\u0026#34;}]}\u0026#39; serviceaccount/build-bot patched Verify if the service account has the secret added:\noc get sa -n node-web-project build-bot -o yaml apiVersion: v1 kind: ServiceAccount metadata: creationTimestamp: \u0026#34;2021-01-12T03:34:32Z\u0026#34; name: build-bot namespace: node-web-project resourceVersion: \u0026#34;53879\u0026#34; selfLink: /api/v1/namespaces/node-web-project/serviceaccounts/build-bot uid: 628067fd-91d1-4cdd-b6a6-88b4f7280ff0 secrets: - name: container-registry-secret - name: build-bot-token-8nl2v Create Pipeline A Pipeline is a collection of Tasks that you want to run as part of your workflow. Each Task in a Pipeline is executed in a pod and by default they run in parallel. However, you can specify the order by using runAfter\nThere are 3 Tasks in below pipeline\n Clone source code Build and push image using Buildah cluster task Syncing argo deployment  apiVersion:tekton.dev/v1alpha1kind:Pipelinemetadata:name:node-web-app-pipelinenamespace:node-web-projectspec:workspaces:- name:shared-workspaceparams:- name:node-web-app-source- name:node-web-app-imagetasks:- name:fetch-repositorytaskRef:kind:ClusterTaskname:git-cloneworkspaces:- name:outputworkspace:shared-workspaceparams:- name:urlvalue:$(params.node-web-app-source)- name:build-and-publish-imageparams:- name:IMAGEvalue:$(params.node-web-app-image)- name:TLSVERIFYvalue:\u0026#39;false\u0026#39;taskRef:kind:ClusterTaskname:buildahrunAfter:- fetch-repositoryworkspaces:- name:sourceworkspace:shared-workspace- name:sync-applicationtaskRef:name:argocd-task-sync-and-waitparams:- name:application-namevalue:node-web-app- name:flagsvalue:--insecure --grpc-web- name:argocd-versionvalue:v1.7.11runAfter:- build-and-publish-imageTriggers Now that the pipeline is setup, we need to setup webhook from GitHub to trigger pipeline. We need to create following resources:\n  A TriggerTemplate act as a blueprint for pipeline resources. It can also be used to define parameters that can then be substituted anywhere within the resource template(s) being defined\napiVersion:triggers.tekton.dev/v1alpha1kind:TriggerTemplatemetadata:name:pipeline-templatenamespace:node-web-projectspec:params:- name:git-repo-url- name:git-repo-name- name:git-revision- name:image-nameresourcetemplates:- apiVersion:tekton.dev/v1beta1kind:PipelineRunmetadata:generateName:$(tt.params.git-repo-name)-pipeline-run-namespace:node-web-projectspec:params:- name:sourcevalue:$(tt.params.git-repo-url)- name:imagevalue:$(tt.params.image-name)pipelineRef:name:node-web-app-pipelineserviceAccountName:build-bottimeout:1h0m0sworkspaces:- name:shared-workspacepersistentVolumeClaim:claimName:tekton-workspace-pvc  A TriggerBinding binds the incoming event data to the template (i.e. git url, repo name, revision, etc\u0026hellip;.)\napiVersion:triggers.tekton.dev/v1alpha1kind:TriggerBindingmetadata:name:pipeline-bindingnamespace:node-web-projectspec:params:- name:git-repo-namevalue:$(body.repository.name)- name:git-repo-urlvalue:$(body.repository.url)- name:git-revisionvalue:$(body.head_commit.id)- name:image-namevalue:docker.io/vikaspogu/$(body.repository.name):$(body.head_commit.id)  An EventListener that will create a pod application bringing together a binding and a template\napiVersion:triggers.tekton.dev/v1alpha1kind:EventListenermetadata:name:el-node-web-appnamespace:defaultspec:serviceAccountName:build-bottriggers:- name:node-web-app-triggerbindings:- ref:pipeline-bindingtemplate:ref:pipeline-template  An OpenShift Route to expose the Event Listener\n$ oc expose svc el-node-web-app $ echo \u0026#34;URL: $(oc get route el-node-web-app --template=\u0026#39;http://{{.spec.host}}\u0026#39;)\u0026#34; http://el-node-web-app-node-web-project.apps.cluster-7d51.sandbox659.opentlc.com   You can learn about Tekton Triggers and OpenShift Pipelines\nCreate ArgoCD App for Web App Resources Create an ArgoCD application via the GUI or command line\n alt argo-pipeline \n Project: default cluster: (URL Of your OpenShift Cluster) namespace should be the name of your OpenShift Project repo url: git repo Target Revision: Head PATH: deployment AutoSync Disabled  Configure Webhooks You will now need to configure GitHub webHook to Tekton Event Listener to start a tekton build from git push\n alt webhooks \nMake a code change and commit, look at build   Push an empty commit to repo\ngit commit -m \u0026#34;empty-commit\u0026#34; --allow-empty \u0026amp;\u0026amp; git push   In OpenShift Console you should see a pipeline run\n alt webhooks \n  Once pipeline is finished. Use OpenShift route to verify app\n  Workspace PVC To use same PVC wit multiple pipelines, a ReadWriteMany pvc has to be created\napiVersion:v1kind:PersistentVolumeClaimmetadata:name:tekton-workspace-pvcnamespace:defaultspec:accessModes:- ReadWriteManyresources:requests:storage:2Gi","date":"2021-01-14T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/tekton-argocd-gitops/","title":"GitOps with Tekton and ArgoCD"},{"content":"Docker buildx on Linux Installation instructions for Ubuntu\nTo execute docker commands without sudo. We need to add username to the docker group\n Find current username by typing who Add username to docker group Reboot system  $ who vikaspogu :0 2020-12-05 10:10 (:0) $ sudo usermod -aG docker vikaspogu $ sudo reboot Enable buildx Create a new config.json file under ~.docker folder and enable experimental feature\n$ mkdir ~/.docker $ vim ~/.docker/config.json { \u0026#34;experimental\u0026#34;: \u0026#34;enabled\u0026#34; } Now you should be able to do multi arch builds\ndocker buildx build -t vikaspogu/test:v0.0.1 . --push --platform linux/arm64 If you encounter below error when trying to build image using buildx. You need to create new build instance\nfailed to solve: rpc error: code = Unknown desc = failed to solve with frontend dockerfile.v0: failed to load LLB: runtime execution on platform linux/arm64 not supported Create build instance The following steps are used to create new build instance for arm64\n List existing buildx platforms Create new build instance named arm64 Inspect build instance to verify arm64 platform exists Set builder instance Build multi platform image  $ docker buildx ls NAME/NODE DRIVER/ENDPOINT STATUS PLATFORMS default docker default default running linux/amd64, linux/386 # create the builder $ docker buildx create --name amr64 --platform linux/amd64,linux/arm64 # start the buildx $ docker buildx inspect arm64 --bootstrap Name: arm64 Driver: docker-container Nodes: Name: arm640 Endpoint: unix:///var/run/docker.sock Status: running Platforms: linux/amd64*, linux/arm64*, linux/riscv64, linux/ppc64le, linux/386, linux/arm/v7, linux/arm/v6, linux/s390x # set current buidler instance $ docker buildx use amr64 # build the multi images $ docker buildx build -t vikaspogu/test:v0.0.1 . --push --platform linux/arm64  If you encounter /bin/sh: Invalid ELF image for this architecture error. Run following docker image and then build\n docker run --rm --privileged multiarch/qemu-user-static --reset -p yes ","date":"2020-12-05T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/docker-buildx-setup/","title":"Setting up docker buildx on Linux"},{"content":"First make sure you have secure boot disabled from the firmware settings. Once you are in grub command line type ls to list all partitions\ngrub\u0026gt;ls (hd0) (hd0,gpt1) (hd1) (hd1,gpt8) (cd0)) Type ls (cd0) to get UUID of device\ngrub\u0026gt;ls (hd0,gpt1) Partition hd0,gpt1: Filesystem type fat - Label `CES_X64FREV`, UUID 4099-DBD9 Partition start-512 Sectors... Note the UUID of you usb drive, shown in above command\nType the following commands\ninsmod part_gpt insmod fat insmod search_fs_uuid insmod chain search --fs-uuid --set=root 409-DBD9 Replace UUID of your device\nNow we select the efi file to boot from\nchainloader /efi/boot/bootx64.efi boot That\u0026rsquo;s it, That should boot the usb drive\n","date":"2020-12-01T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/boot-from-usb-through-grub-menu/","title":"Boot from USB through grub menu"},{"content":"In this article, I will share the setup for enabling Authentication and Authorization in OpenShift Service Mesh with Keycloak\nInstalling OpenShift Service Mesh Follow the Installing Red Hat OpenShift Service Mesh guide for setup\nEnable following configuration in your ServiceMeshControlPlane resource\n Strict mTLS across the mesh Automatic istio route creation  apiVersion:maistra.io/v2kind:ServiceMeshControlPlanespec:version:v1.1security:controlPlane:mtls:truegateways:OpenShiftRoute:enabled:trueKeycloak Keycloak is an open-source identity and access management application that uses open protocols and is easily integrated with other providers. It is the open-source project base of Red Hat Single Sign-on\nDeploying Red Hat Single Sign-on The easiest way to deploy SSO is from the operator hub\n sso-operator \nFollow the Keycloak identity provider article for adding new secuity realm, client, role, user\nDeploying Bookinfo example application Create a new namespace\noc new-project bookinfo Edit the default Service Mesh Member Roll YAML and add bookinfo to the members list\napiVersion:maistra.io/v1kind:ServiceMeshMemberRollmetadata:name:defaultspec:members:- bookinfoFrom the CLI, deploy the Bookinfo application in the bookinfo project by applying the bookinfo.yaml file\noc apply -n bookinfo -f https://raw.githubusercontent.com/Maistra/istio/maistra-2.0/samples/bookinfo/platform/kube/bookinfo.yaml Create the ingress gateway by applying the bookinfo-gateway.yaml file\noc apply -n bookinfo -f https://raw.githubusercontent.com/Maistra/istio/maistra-2.0/samples/bookinfo/networking/bookinfo-gateway.yaml Set the value for the GATEWAY_URL parameter\noc get routes -n istio-system | grep bookinfo export GATEWAY_URL=$(oc -n istio-system get route bookinfo-gateway-pl2rw -o jsonpath=\u0026#39;{.spec.host}\u0026#39;) Adding default destination rules\nI have enabled global mutual TLS in the control plane, so I’ll deploy the destination rule with all mtls\noc apply -n bookinfo -f https://raw.githubusercontent.com/Maistra/istio/maistra-2.0/samples/bookinfo/networking/destination-rule-all-mtls.yaml Verifying the Bookinfo installation\nRun this command to confirm that Bookinfo is deployed\ncurl -o /dev/null -s -w \u0026#34;%{http_code}\\n\u0026#34; http://$GATEWAY_URL/productpage Authentication Enabling User-End Authentication Now it is time to enable end-user authentication\nThe first thing you need to do is validate that it is possible to communicate between all services without authentication\ncurl -k -o /dev/null -w \u0026#34;%{http_code}\u0026#34; http://$GATEWAY_URL/productpage 200 You can create the end-user authentication policy\ncat \u0026lt;\u0026lt;EOF | oc apply -n bookinfo -f - apiVersion: authentication.istio.io/v1alpha1 kind: Policy metadata: name: \u0026#34;productpage-jwt\u0026#34; namespace: \u0026#34;bookinfo\u0026#34; spec: targets: - name: productpage peers: - mtls: {} origins: - jwt: issuer: \u0026#34;https://keycloak-sso.apps.amp01.lab.amp.aapaws/auth/realms/istio\u0026#34; jwksUri: \u0026#34;https://keycloak-sso.apps.amp01.lab.amp.aapaws/auth/realms/istio/protocol/openid-connect/certs\u0026#34; audiences: - customer triggerRules: - excludedPaths: - prefix: /healthz principalBinding: USE_ORIGIN EOF NOTE: If you see Origin authentication failed. after passing right access token and url. Verify your istio-pilot pods for any x509: certificate signed by unknown authority if thats the case follow this workaround\nThen let’s run the curl again\ncurl -k http://$GATEWAY_URL/productpage And you will see something like\nOrigin authentication failed. Set the value for the TOKEN parameter from keyclock\nexport TOKEN=$(curl -sk --data \u0026#34;username=demo\u0026amp;password=demo\u0026amp;grant_type=password\u0026amp;client_id=istio\u0026#34; https://keycloak-sso.apps.amp01.lab.amp.aapaws/auth/realms/istio/protocol/openid-connect/token | jq \u0026#34;.access_token\u0026#34;) Then let’s run the curl again, this time with the token\ncurl -k -o /dev/null -w \u0026#34;%{http_code}\u0026#34; -H \u0026#34;Authorization: Bearer $TOKEN\u0026#34; http://$GATEWAY_URL/productpage 200 Authorization Create a deny-all policy in the namespace. The policy doesn’t have a selector field, which applies the policy to every workload in the namespace. The spec: field of the policy has the empty value {}. The empty value means that no traffic is permitted, effectively denying all requests\n$ cat \u0026lt;\u0026lt;EOF | oc apply -n bookinfo -f - apiVersion: security.istio.io/v1beta1 kind: AuthorizationPolicy metadata: name: deny-all spec: {} EOF Once the policy takes effect, verify that mesh rejected the curl connection to the workload\n$ curl -k -H \u0026#34;Authorization: Bearer $TOKEN\u0026#34; http://$GATEWAY_URL/productpage RBAC: access denied To give read access to the productpage workload, create the policy that applies to workload with label app: productpage and allows users with roles customer to access it with all method\n$ cat \u0026lt;\u0026lt;EOF | oc apply -n bookinfo -f - apiVersion: security.istio.io/v1beta1 kind: AuthorizationPolicy metadata: name: \u0026#34;productpage-authz\u0026#34; namespace: \u0026#34;bookinfo\u0026#34; spec: selector: matchLabels: app: productpage rules: - to: - operation: methods: [\u0026#34;*\u0026#34;] when: - key: request.auth.claims[roles] values: [\u0026#34;customer\u0026#34;] EOF Wait for the newly defined policy to take effect\nAfter the policy takes effect, verify the connection to the httpbin workload succeeds\ncurl -k -o /dev/null -w \u0026#34;%{http_code}\u0026#34; -H \u0026#34;Authorization: Bearer $TOKEN\u0026#34; http://$GATEWAY_URL/productpage 200 However, you can see the following errors on the page\n Error fetching product details Error fetching product reviews on the page  Run the following command to create the details-viewer policy to allow the productpage workload, which issues requests using the cluster.local/ns/bookinfo/sa/bookinfo-productpage service account, to access the details workload through GET methods\noc apply -f - \u0026lt;\u0026lt;EOF apiVersion: \u0026#34;security.istio.io/v1beta1\u0026#34; kind: \u0026#34;AuthorizationPolicy\u0026#34; metadata: name: \u0026#34;details-viewer\u0026#34; namespace: bookinfo spec: selector: matchLabels: app: details rules: - from: - source: principals: [\u0026#34;cluster.local/ns/bookinfo/sa/bookinfo-productpage\u0026#34;] to: - operation: methods: [\u0026#34;GET\u0026#34;] EOF Run the following command to create a policy reviews-viewer to allow the productpage workload, which issues requests using the cluster.local/ns/bookinfo/sa/bookinfo-productpage service account, to access the reviews workload through GET methods\noc apply -f - \u0026lt;\u0026lt;EOF apiVersion: \u0026#34;security.istio.io/v1beta1\u0026#34; kind: \u0026#34;AuthorizationPolicy\u0026#34; metadata: name: \u0026#34;reviews-viewer\u0026#34; namespace: bookinfo spec: selector: matchLabels: app: reviews rules: - from: - source: principals: [\u0026#34;cluster.local/ns/bookinfo/sa/bookinfo-productpage\u0026#34;] to: - operation: methods: [\u0026#34;GET\u0026#34;] EOF Point your browser at the Bookinfo productpage (http://$GATEWAY_URL/productpage). Now, you should see the “Bookinfo Sample” page with “Book Details” on the lower left part, and “Book Reviews” on the lower right part. However, in the “Book Reviews” section, there is an error Ratings service currently unavailable\nThis is because the reviews workload doesn’t have permission to access the ratings workload. To fix this issue, you need to grant the reviews workload access to the ratings workload. Next, we configure a policy to grant the reviews workload that access\nRun the following command to create the ratings-viewer policy to allow the reviews workload, which issues requests using the cluster.local/ns/bookinfo/sa/bookinfo-reviews service account, to access the ratings workload through GET methods\noc apply -f - \u0026lt;\u0026lt;EOF apiVersion: \u0026#34;security.istio.io/v1beta1\u0026#34; kind: \u0026#34;AuthorizationPolicy\u0026#34; metadata: name: \u0026#34;ratings-viewer\u0026#34; namespace: bookinfo spec: selector: matchLabels: app: ratings rules: - from: - source: principals: [\u0026#34;cluster.local/ns/bookinfo/sa/bookinfo-reviews\u0026#34;] to: - operation: methods: [\u0026#34;GET\u0026#34;] EOF Point your browser at the Bookinfo productpage (http://$GATEWAY_URL/productpage). You should see the “black” and “red” ratings in the “Book Reviews” section\n","date":"2020-11-12T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/servicemesh-jwt-auth-authz-keycloack/","title":"End User Auth and Authz with OpenShift Service Mesh and Keycloak"},{"content":"Loki Promtail Enable syslog, do this on each host and replace target IP (and maybe port) with you syslog externalIP that is in helm values for promtail\npromtail:serviceMonitor:enabled:trueextraScrapeConfigs:- job_name:syslogsyslog:listen_address:0.0.0.0:1514label_structured_data:yeslabels:job:\u0026#34;syslog\u0026#34;relabel_configs:- source_labels:[\u0026#34;__syslog_connection_ip_address\u0026#34;]target_label:\u0026#34;ip_address\u0026#34;- source_labels:[\u0026#34;__syslog_message_severity\u0026#34;]target_label:\u0026#34;severity\u0026#34;- source_labels:[\u0026#34;__syslog_message_facility\u0026#34;]target_label:\u0026#34;facility\u0026#34;- source_labels:[\u0026#34;__syslog_message_hostname\u0026#34;]target_label:\u0026#34;host\u0026#34;syslogService:enabled:truetype:LoadBalancerport:1514externalIPs:- 192.168.42.155Create file /etc/rsyslog.d/50-promtail.conf with the following content:\nmodule(load=\u0026#34;omprog\u0026#34;) module(load=\u0026#34;mmutf8fix\u0026#34;) action(type=\u0026#34;mmutf8fix\u0026#34; replacementChar=\u0026#34;?\u0026#34;) action(type=\u0026#34;omfwd\u0026#34; protocol=\u0026#34;tcp\u0026#34; target=\u0026#34;192.168.42.155\u0026#34; port=\u0026#34;1514\u0026#34; Template=\u0026#34;RSYSLOG_SyslogProtocol23Format\u0026#34; TCP_Framing=\u0026#34;octet-counted\u0026#34; KeepAlive=\u0026#34;on\u0026#34;) Restart rsyslog and view status\nsudo systemctl restart rsyslog sudo systemctl status rsyslog In Grafana, on the explore tab, you should now be able to view you hosts logs, e.g. this query {host=\u0026quot;k3s-master\u0026quot;}\n","date":"2020-11-04T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/loki-rsyslog-k3s/","title":"Syslog with Loki Promtail"},{"content":"Key benefits of Helm is that it helps reduce the amount of configuration a user needs to provide to deploy applications to Kubernetes. With Helm, we can have a single chart that can deploy all the microservices.\nUnique ServiceAccount Recently we wanted to create a unique service account for each microservice, so all microservices don\u0026rsquo;t share same service account using helm template. In our example, we will append the release name with the service account name.\nUsing join function {{(list .Values.serviceAccount.name (include \u0026#34;openjdk.fullname\u0026#34; .) | join \u0026#34;-\u0026#34;) }} Adding fail condition {{- if .Values.serviceAccount.name -}} {{(list .Values.serviceAccount.name (include \u0026#34;openjdk.fullname\u0026#34; .) | join \u0026#34;-\u0026#34;) }} {{- else -}} {{- fail \u0026#34;Please enter a name for service account to create.\u0026#34; }} {{- end -}}Full example\n{{- define \u0026#34;openjdk.serviceAccountName\u0026#34; -}}{{- if .Values.serviceAccount.create -}} {{- if .Values.serviceAccount.name -}} {{(list .Values.serviceAccount.name (include \u0026#34;openjdk.fullname\u0026#34; .) | join \u0026#34;-\u0026#34;) }} {{- else -}} {{- fail \u0026#34;Please enter a name for service account to create.\u0026#34; }} {{- end -}}{{- else -}} {{- if .Values.serviceAccount.name -}} {{(list .Values.serviceAccount.name (include \u0026#34;openjdk.fullname\u0026#34; .) | join \u0026#34;-\u0026#34;) }} {{- else -}} \u0026#34;default\u0026#34;{{- end -}}{{- end -}}{{- end -}}Another way to manipulate strings in helpers.tpl is using printf\n{{- define \u0026#34;ocp-openjdk.hostname\u0026#34; -}}{{- printf \u0026#34;%s-%s%s\u0026#34; .Release.Name .Release.Namespace (.Values.subdomain | default \u0026#34;.apps.amp01.nonprod\u0026#34; ) -}}{{- end -}}Resources  Sprig functions  ","date":"2020-10-08T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/helm-join-function/","title":"Helm join strings in a named template"},{"content":"AdGuard AdGuard Home is a network-wide software for blocking ads \u0026amp; tracking\nAdguard is similar to Pi-Hole with more features. Comparison of Adguard to Pi-Hole\nThe below configuration has worked for me. I am a big fan of helm charts and I\u0026rsquo;ll be using AdGuard chart\nConfigure chart Pull chart locally\nhelm repo add billimek https://billimek.com/billimek-charts/ helm fetch billimek/adguard-home Update deployment to use hostNetwork\n#templates/deployment.yaml...spec:hostNetwork:truesecurityContext:...Enable configAsCode, update bind_host to Kubernetes host IP in values.yaml\n# values.yamlconfigAsCode:enabled:trueconfig:bind_host:192.168.0.101bind_port:3000dns:bind_host:192.168.0.101Update securityContext to run as a privileged pod, drop all capabilities and add NET_BIND_SERVICE\n# values.yamlsecurityContext:privileged:truecapabilities:drop:- ALLadd:- NET_BIND_SERVICEAdd nodeSelector to assign pod to that node\n# values.yamlnodeSelector:kubernetes.io/hostname:node3Deploy helm chart\nhelm install adguard-home Wait for AdGuard pods\nkubectl get pods NAME READY STATUS RESTARTS AGE adguard-adguard-home-67975f7768-v6bg9 1/1 Running 0 43h Configure your devices to use your AdGuard Home Now, once we\u0026rsquo;ve established that AdGuard Home is deployed, you can use it on other computers in your network by changing their system DNS settings to use Kubernetes node\u0026rsquo;s IP address (which is 192.168.0.101 in our case).\n","date":"2020-08-19T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/adguardhome-kubernetes/","title":"AdGuard on Kubernetes"},{"content":"In one of my previous posts, I have discussed configuring multibranch pipeline seed jobs using Jenkins configuration as code plugin\nThis is an example of configuring a declarative pipeline job from bitbucket repo, running at midnight every day\n- script:\u0026gt;pipelineJob(\u0026#39;sample-job\u0026#39;) { definition { cpsScm { scriptPath \u0026#39;job1/Jenkinsfile\u0026#39; ## If jenkins job is in a nested folder scm { git { remote { url \u0026#39;https://github.com/Vikaspogu/sample-repo\u0026#39; credentials \u0026#39;sample-creds\u0026#39; } branch \u0026#39;*/master\u0026#39; extensions {} } } triggers { cron(\u0026#39;@midnight\u0026#39;) } } } }","date":"2020-08-18T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/jenkins-seed-job/","title":"Configure jenkins pipeline job"},{"content":"Every organization has policies. Some are essential to meet governance and legal requirements. Others help ensure adherence to best practices and institutional conventions. Attempting to ensure compliance manually would be error-prone and frustrating\nOPA lets you specific policy as code using OPA policy language Rego\nIn this post, I\u0026rsquo;ll share my experience deploying OPA Gatekeeper on OpenShift and creating few policies for demonstartions. This post is not an introduction to OPA, refer to for intro\nGatekeeper introduces native kubernetes CRDs for instantiating policies\nInstallation For installation, make sure you have cluster admin permissions\nLet\u0026rsquo;s start by adding the admission.gatekeeper.sh/ignore label to non-user namespaces, so that all the resources in the labeled project are exempted from admission webhook\noc login --token=l4xjpLh0e722B2_i7iWAbPsUNOb6vPDaAXnqhH563oU --server=https://api.cluster-1d4d.sandbox702.opentlc.com:6443 for namespace in $(oc get namespaces -o jsonpath=\u0026#39;{.items[*].metadata.name}\u0026#39; | xargs); do if [[ \u0026#34;${namespace}\u0026#34; =~ OpenShift.* ]] || [[ \u0026#34;${namespace}\u0026#34; =~ kube.* ]] || [[ \u0026#34;${namespace}\u0026#34; =~ default ]]; then oc patch namespace/${namespace} -p=\u0026#39;{\u0026#34;metadata\u0026#34;:{\u0026#34;labels\u0026#34;:{\u0026#34;admission.gatekeeper.sh/ignore\u0026#34;:\u0026#34;true\u0026#34;}}}\u0026#39; else # Probably a users project, so leave it alone echo \u0026#34;Skipping: ${namespace}\u0026#34; fi done Deploying a Release using Prebuilt Image Deploy Gatekeeper with prebuilt image\noc apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml Remove securityContext and annotations from the deployments\noc patch Deployment/gatekeeper-audit --type json -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;remove\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/template/metadata/annotations\u0026#34;}]\u0026#39; -n gatekeeper-system oc patch Deployment/gatekeeper-controller-manager --type json -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;remove\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/template/metadata/annotations\u0026#34;}]\u0026#39; -n gatekeeper-system oc patch Deployment/gatekeeper-audit --type json --patch \u0026#39;[{ \u0026#34;op\u0026#34;: \u0026#34;remove\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/template/spec/containers/0/securityContext\u0026#34; }]\u0026#39; -n gatekeeper-system oc patch Deployment/gatekeeper-controller-manager --type json --patch \u0026#39;[{ \u0026#34;op\u0026#34;: \u0026#34;remove\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/template/spec/containers/0/securityContext\u0026#34; }]\u0026#39; -n gatekeeper-system Wait for Gatekeeper to be ready\noc get pods -n gatekeeper-system NAME READY STATUS RESTARTS AGE gatekeeper-audit-7c84869dbf-r5p87 1/1 Running 0 2m34s gatekeeper-controller-manager-ff58b6688-9tbxx 1/1 Running 0 3m23s gatekeeper-controller-manager-ff58b6688-njfnd 1/1 Running 0 2m54s gatekeeper-controller-manager-ff58b6688-vlrsl 1/1 Running 0 3m11s Gatekeeper uses the OPA Constraint Framework to describe and enforce policy\nDefining constraints Constraints can be defined by creating a CRD (CustomResourceDefinition) with the template of the constraint you want. Let’s look at a template which enforces that only secure routes are created in the cluster\napiVersion:templates.gatekeeper.sh/v1beta1kind:ConstraintTemplatemetadata:name:k8sallowedroutesspec:crd:spec:names:kind:K8sAllowedRoutestargets:- target:admission.k8s.gatekeeper.shrego:|package k8sallowedroutes violation[{\u0026#34;msg\u0026#34;: msg}] { not input.review.object.spec.tls msg := sprintf(\u0026#34;\u0026#39;%v\u0026#39; route must be a secured route. non secured routes are not permitted\u0026#34;, [input.review.object.metadata.name]) }It will get the route and check if tls object is specified. If this is not true, the violation block continues and the violation is triggered with the corresponding message\nEnforcing constraints These constrains which you defined now need to be enforced. This is done by defining a constraint which will use the template specified earlier.\napiVersion:constraints.gatekeeper.sh/v1beta1kind:K8sAllowedRoutesmetadata:name:secure-routespec:match:kinds:- apiGroups:[\u0026#34;route.OpenShift.io\u0026#34;]kinds:[\u0026#34;Route\u0026#34;]This policy will use the CRD “K8sAllowedRoutes” which we had already defined. Matching is done by specifying on which API group it has to be enforced\n nonsecure_route \nSome constraints are impossible to write without access to more state than just the object under test. For example, it is impossible to know if an route\u0026rsquo;s hostname is unique among all routes unless a rule has access to all other routes. To make such rules possible, we enable syncing of data into OPA.\napiVersion:config.gatekeeper.sh/v1alpha1kind:Configmetadata:name:confignamespace:\u0026#34;gatekeeper-system\u0026#34;spec:sync:syncOnly:- group:\u0026#34;\u0026#34;version:\u0026#34;v1\u0026#34;kind:\u0026#34;Namespace\u0026#34;- group:\u0026#34;route.OpenShift.io\u0026#34;version:\u0026#34;v1\u0026#34;kind:\u0026#34;Route\u0026#34;Let\u0026rsquo;s create another policy which prevents conflicting routes from being created\napiVersion:templates.gatekeeper.sh/v1beta1kind:ConstraintTemplatemetadata:name:k8suniqueroutehostspec:crd:spec:names:kind:K8sUniqueRouteHosttargets:- target:admission.k8s.gatekeeper.shrego:|package k8suniqueroutehost identical(obj, review) { obj.metadata.namespace == review.object.metadata.namespace obj.metadata.name == review.object.metadata.name } violation[{\u0026#34;msg\u0026#34;: msg}] { input.review.kind.kind == \u0026#34;Route\u0026#34; re_match(\u0026#34;^(route.OpenShift.io)$\u0026#34;, input.review.kind.group) host := input.review.object.spec.host other := data.inventory.namespace[ns][otherapiversion][\u0026#34;Route\u0026#34;][name] re_match(\u0026#34;^(route.OpenShift.io)/.+$\u0026#34;, otherapiversion) other.spec.host == host not identical(other, input.review) msg := sprintf(\u0026#34;Route host conflicts with an existing route \u0026lt;%v\u0026gt;\u0026#34;, [host]) }apiVersion:constraints.gatekeeper.sh/v1beta1kind:K8sUniqueRouteHostmetadata:name:unique-route-hostspec:match:kinds:- apiGroups:[\u0026#34;route.OpenShift.io\u0026#34;]kinds:[\u0026#34;Route\u0026#34;]Resources  Open Policy Agent OPA Gatekeeper Test framework  ","date":"2020-08-18T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/opa-gatekeeper-openshift/","title":"OPA Gatekeeper on OpenShift"},{"content":"This is how you can calculate days between two dates in Jenkins pipeline. @NonCPS annotation is useful when you have methods which use objects that aren\u0026rsquo;t serializable\nimport java.text.SimpleDateFormat stages { stage(\u0026#34;Calculate days\u0026#34;) { steps { script { def daysRemaining = getRemainingDays(\u0026#34;2020-06-25\u0026#34;) } } } } } @NonCPS def getRemainingDays(previousDate){ def currentDate = new Date() String currentTimeFormat= currentDate.format(\u0026#34;yyyy-MM-dd\u0026#34;) def oldDate = new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;).parse(previousDate) return currentTimeFormat-oldDate } Calculate if date is greater than 14 days\nimport java.time.LocalDate import java.time.format.DateTimeFormatter stages { stage(\u0026#34;Check if date is older than 14 days\u0026#34;) { steps { script { if (checkIfOtherThan(\u0026#34;2020-06-25\u0026#34;)){ println \u0026#34;Date is greater than 14 days\u0026#34; } } } } } } @NonCPS def checkIfOlderThan(previousDate){ def dateFormat = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd\u0026#34;) def currentDate = LocalDate.now().format(dateFormat); def projectpreviousDate = LocalDate.parse(previousDate, dateFormat) if (LocalDate.parse(currentDate, dateFormat).minusDays(14) \u0026gt; projectpreviousDate) { return true; } return false; } ","date":"2020-07-07T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/jenkins-date-difference/","title":"Jenkins pipeline date helper functions"},{"content":"Deploying Jenkins on Kubernetes provides important benefits over a standard VM-based deployment. For example, gaining the ability to have project-specific Jenkins slaves (agents) on demand, instead of having a pool of VMs idle waiting for a job.\nJenkins can be easily deployed using Helm, OpenShift using jenkins catalog\nAs everyone has experienced setting up Jenkins is a complex process, as both Jenkins and its plugins require some tuning and configuration, with dozens of parameters to set within the web UI manage section\nJenkins Config as code Configuration as code gives you an opinionated way to configure jenkins based on yaml files\nIn this post will cover jenkins configuration code on OpenShift\n Mount jenkins config as a configmap and load configuration Updated configuration file to automate creation of  credentials script approval signatures shared libraries multibranch pipeline seed jobs    Install Plugin First, lets install configuration-as-code plugins in jenkins. In OpenShift you can easily install plugins by adding INSTALL_PLUGINS environment variable to deploymentconfig\n....env:- name:INSTALL_PLUGINSvalue:\u0026#34;configuration-as-code:1.35,configuration-as-code-support:1.18,configuration-as-code-groovy:1.1Create ConfigMap Create a configmap from jenkins-config yaml and mount it as a volume at /var/jenkins_config location. Configuration can be now loaded from /var/jenkins_config/jenkins-config.yaml path\noc create configmap jenkins-config --from-file jenkins-config.yaml ....volumeMounts:- mountPath:/var/jenkins_configname:jenkins-configdnsPolicy:ClusterFirstrestartPolicy:Alwaysvolumes:- name:jenkins-configconfigMap:name:jenkins-configMount Secret Since we can have jenkins config in git repo we don\u0026rsquo;t want to hardcode the secrets as it is a security risk. The easiest way to automate credential in jenkins configuration is to create a OpenShift secret, add that secret as a environment variable to deployment config\noc create secret generic github-ssh --from-file=ssh-privatekey=github-ssh/ oc create secret generic jenkins-credentials --from-literal=OCP_SA=\u0026#34;qwerty26sds99ie9kcsd\u0026#34; --from-literal=GITHUB_PASSWORD=\u0026#34;dummypassword\u0026#34; Mount secrets into the container\n....env:....- name:OCP_SAvalueFrom:secretKeyRef:name:jenkins-credentialskey:OCP_SA- name:GITHUB_SSHvalueFrom:secretKeyRef:name:github-sshkey:ssh-privatekey- name:GITHUB_PASSWORDvalueFrom:secretKeyRef:name:jenkins-credentialskey:GITHUB_PASSWORD....credentials:system:domainCredentials:- credentials:- fileSystemServiceAccountCredential:id:\u0026#34;1a12dfa4-7fc5-47a7-aa17-cc56572a41c7\u0026#34;scope:GLOBAL- basicSSHUserPrivateKey:description:\u0026#34;github ssh credentials\u0026#34;id:\u0026#34;github-ssh\u0026#34;privateKeySource:directEntry:privateKey:${GITHUB_SSH}scope:GLOBALusername:\u0026#34;github-user\u0026#34;- OpenShiftToken:id:\u0026#34;jenkins-ocp-token\u0026#34;scope:GLOBALsecret:${OCP_SA}- usernamePassword:description:\u0026#34;github user credentials\u0026#34;id:\u0026#34;github-user\u0026#34;password:${GITHUB_PASSWORD}scope:GLOBALusername:\u0026#34;github-user\u0026#34;Example Configs Security script approval security:scriptApproval:approvedSignatures:- \u0026#34;method java.text.DateFormat parse java.lang.String\u0026#34;Global shared library unclassified:globalLibraries:libraries:- defaultVersion:\u0026#34;master\u0026#34;name:\u0026#34;shared-pipeline\u0026#34;retriever:modernSCM:scm:git:credentialsId:\u0026#34;github-ssh\u0026#34;id:\u0026#34;shared-pipeline\u0026#34;remote:\u0026#34;git@github.com:vikaspogu/jenkins-shared.git\u0026#34;Multibranch job Multibranch seed job with periodic polling, traits for branch discovery\njobs:- script:\u0026gt;multibranchPipelineJob(\u0026#34;sample-repo\u0026#34;) { branchSources { branchSource { source { github { //This is a unique identifier if not set, pipeline will be //indexed and jobs will be kicked off everytime new config is applied id(\u0026#34;5bb970c2-766b-4588-8cf8-e077bfec23a0\u0026#34;) credentialsId(\u0026#34;github-user\u0026#34;) repoOwner(\u0026#34;vikaspogu\u0026#34;) repository(\u0026#34;sample-repo\u0026#34;) traits { cloneOptionTrait { extension { shallow (false) noTags (false) reference (null) depth(1) honorRefspec (false) timeout (10) } } } } } } } configure { def traits = it / sources / data / \u0026#39;jenkins.branch.BranchSource\u0026#39; / source / traits traits \u0026lt;\u0026lt; \u0026#39;com.cloudbees.jenkins.plugins.bitbucket.BranchDiscoveryTrait\u0026#39; { strategyId(3) // detect all branches -refer the plugin source code for various options } } configure { def traits = it / sources / data / \u0026#39;jenkins.branch.BranchSource\u0026#39; / source / traits traits \u0026lt;\u0026lt; \u0026#39;com.cloudbees.jenkins.plugins.bitbucket.OriginPullRequestDiscoveryTrait\u0026#39; { strategyId(2) } } configure { def traits = it / sources / data / \u0026#39;jenkins.branch.BranchSource\u0026#39; / source / traits traits \u0026lt;\u0026lt; \u0026#39;com.cloudbees.jenkins.plugins.bitbucket.TagDiscoveryTrait\u0026#39; {} } orphanedItemStrategy { discardOldItems { numToKeep(15) } } triggers { periodic(2) } }","date":"2020-07-06T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/jenkins-config-as-code-openshift/","title":"OpenShift Jenkins configuration via JCasC plugin"},{"content":"Pi Garage Door Opener There are many articles out there which demonstartes how to use a raspberry pi as a DIY garage door opener project. Few are outdated and not deployed using containers images. I found couple good solutions on google but i wasn\u0026rsquo;t able to run them on kubernetes cluster either due to older packages or no enough information. I decided to build my own solution from different sources of information i found\nWhat we\u0026rsquo;ll cover in this post\n setup nodejs project to simulate a button create a container from nodejs application deploy container on kubernetes cluster  Kudos! to author for this awesome article on showing us how to connect relay and magentic switch to raspberry pi for our purpose.\nOnce you are done wiring up all components. Let\u0026rsquo;s start setting up our Nodejs application\nApplication setup Create a npm project\nmkdir garage-pi \u0026amp;\u0026amp; cd garage-pi npm init -y We\u0026rsquo;ll be using node-rpio package which provides access to the Raspberry Pi GPIO interface\nInstall node-rpio and express packages\nnpm i rpio express -S Create an express app which starts on port 8080 in server.js file\n\u0026#34;use strict\u0026#34;; const express = require(\u0026#34;express\u0026#34;); const rpio = require(\u0026#34;rpio\u0026#34;); const app = express(); const PORT = 8080; app.use(\u0026#34;/assets\u0026#34;, express.static(\u0026#34;assets\u0026#34;)); app.listen(PORT); console.log(\u0026#34;Running on http://localhost:\u0026#34; + PORT); Below code let\u0026rsquo;s you simulate a button press; In our case pin number is 19. First, we want to output to low and set the pin to high after 1000ms. Please refer to rpio repo for more explaination\nconst openPin = process.env.OPEN_PIN || 19; const relayPin = process.env.RELAY_PIN || 11; app.get(\u0026#34;/relay\u0026#34;, function (req, res) { // Simulate a button press  rpio.write(relayPin, rpio.LOW); setTimeout(function () { rpio.write(relayPin, rpio.HIGH); res.send(\u0026#34;done\u0026#34;); }, 1000); }); To get the state of pin\nfunction getState() { return { open: !rpio.read(openPin), }; } app.get(\u0026#34;/status\u0026#34;, function (req, res) { res.send(JSON.stringify(getState())); }); Complete server.js file\n\u0026#34;use strict\u0026#34;; const express = require(\u0026#34;express\u0026#34;); const rpio = require(\u0026#34;rpio\u0026#34;); const app = express(); const PORT = 8080; const openPin = process.env.OPEN_PIN || 19; const relayPin = process.env.RELAY_PIN || 11; app.use(\u0026#34;/assets\u0026#34;, express.static(\u0026#34;assets\u0026#34;)); function getState() { return { open: !rpio.read(openPin), }; } app.get(\u0026#34;/status\u0026#34;, function (req, res) { res.send(JSON.stringify(getState())); }); app.get(\u0026#34;/relay\u0026#34;, function (req, res) { // Simulate a button press  rpio.write(relayPin, rpio.LOW); setTimeout(function () { rpio.write(relayPin, rpio.HIGH); res.send(\u0026#34;done\u0026#34;); }, 1000); }); app.listen(PORT); console.log(\u0026#34;Running on http://localhost:\u0026#34; + PORT); Container image  Create a dockerfile with multi-stage builds using nodejs arm image Install necessary python package for rpio Build docker image Publish docker image to your repo in docker hub Create new kubernetes deployment and service  # Fetch node_modules for backend, nothing here except# the node_modules dir ends up in the final imageFROMarm32v7/node:12.18-alpine as builderRUN mkdir /appWORKDIR/appENV PATH /app/node_modules/.bin:$PATHCOPY package.json /app/package.jsonRUN apk add --no-cache make gcc g++ python \u0026amp;\u0026amp; \\  npm install --production --silent \u0026amp;\u0026amp; \\  apk del make gcc g++ pythonRUN npm install# Add the files to arm imageFROMarm32v7/node:12.18-alpineRUN mkdir /appWORKDIR/appENV PATH /app/node_modules/.bin:$PATH# Same as earlier, be specific or copy everythingADD package.json /app/package.jsonADD package-lock.json /app/package-lock.jsonADD . /appCOPY --from=builder /app/node_modules /app/node_modulesENV PORT=8080 EXPOSE8080CMD [ \u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34; ]Docker buildx feature lets you build arm based images on mac or windows system\ndocker buildx build --platform linux/arm64 -t \u0026lt;docker-username\u0026gt;/garage-pi . docker push \u0026lt;docker-username\u0026gt;/garage-pi Create a new deployment named garage-pi that runs earlier published image.\nkind: Deployment apiVersion: apps/v1 metadata: name: garage-pi labels: app.kubernetes.io/name: garage-pi spec: replicas: 1 selector: matchLabels: app.kubernetes.io/instance: garage-pi app.kubernetes.io/name: garage-pi template: metadata: creationTimestamp: null labels: app.kubernetes.io/instance: garage-pi app.kubernetes.io/name: garage-pi spec: volumes: - name: dev-snd hostPath: path: /dev/mem type: \u0026#39;\u0026#39; containers: - name: garage-pi image: \u0026#39;\u0026lt;docker-username\u0026gt;/garage-pi:latest\u0026#39; ##update username here ports: - name: http containerPort: 8080 protocol: TCP resources: {} volumeMounts: - name: dev-snd mountPath: /dev/mem livenessProbe: httpGet: path: / port: http scheme: HTTP readinessProbe: httpGet: path: / port: http scheme: HTTP imagePullPolicy: Always securityContext: privileged: true restartPolicy: Always Create a service for an garage-pi deployment, which serves on port 8080 and connects to the containers on port 8080.\nkubectl expose deployment nginx --port=8080 --target-port=8080 That\u0026rsquo;s it, you should be able to hit endpoint and simulate button click!\nFrontend For frontend of application we\u0026rsquo;ll use pugjs templating engine\nInstall pug package\nnpm i pug -S  add views folder in root directory and create a new index.pug file in views folder wire up templating engine with application render index page on root / endpoint integrate button with /relay endpoint, which will open/closed garage door  doctype html head meta(charset=\u0026#39;utf-8\u0026#39;) meta(name=\u0026#39;viewport\u0026#39;, content=\u0026#39;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#39;) meta(name=\u0026#39;description\u0026#39;, content=\u0026#39;\u0026#39;) meta(name=\u0026#39;author\u0026#39;, content=\u0026#39;\u0026#39;) title Garage Opener .text-center form.form-signin(method=\u0026#39;POST\u0026#39;, action=\u0026#39;/relay\u0026#39;) h1.h1.mb-2.font-weight-normal(style=\u0026#39;color: #FFFFFF\u0026#39;) Garage Door .text-center .form-signin .text-center #open h1.h2.mb-3.font-weight-normal(style=\u0026#39;color: #CF6679\u0026#39;) The Door is Open \u0026amp;#xF62B; button#mainButton.btn.btn-lg.btn-primary.btn-block(type=\u0026#39;submit\u0026#39;) Close app.set(\u0026#34;views\u0026#34;, path.join(__dirname, \u0026#34;views\u0026#34;)); app.set(\u0026#34;view engine\u0026#34;, \u0026#34;pug\u0026#34;); app.get(\u0026#34;/\u0026#34;, function (req, res) { res.render(\u0026#34;index\u0026#34;, getState()); }); Twilio Integration (Optional) Install dotenv, twilio and node-schedule packages\nnpm i dotenv node-schedule twilio -S Create a .env file at root of the project and add your twilio auth key, account sid and phone number\nTWILIO_ACCOUNT_SID= TWILIO_AUTH_TOKEN= TWILIO_PHONE_NUMBER= Create a twilio.js file, add below code\nrequire(\u0026#34;dotenv\u0026#34;).config(); const accountSid = process.env.TWILIO_ACCOUNT_SID; const authToken = process.env.TWILIO_AUTH_TOKEN; const sendSms = (phone, message) =\u0026gt; { const client = require(\u0026#34;twilio\u0026#34;)(accountSid, authToken); client.messages .create({ body: message, from: process.env.TWILIO_PHONE_NUMBER, to: phone, }) .then((message) =\u0026gt; console.log(message.sid)); }; module.exports = sendSms; Schedule a job for every 15mins to check state of garage door, if door is open we\u0026rsquo;ll send a message\nconst sendSms = require(\u0026#34;./twilio\u0026#34;); ... ... schedule.scheduleJob(\u0026#34;*/15 * * * *\u0026#34;, function () { var status = JSON.parse(JSON.stringify(getState())); if (status.open) { sendSms(\u0026#34;\u0026lt;YOUR-NUMBER\u0026gt;\u0026#34;, \u0026#34;Garage door is open 🔥\u0026#34;); } }); ","date":"2020-07-05T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/pi-garage-k3s/","title":"Raspberry Pi garage door opener using nodejs on k3s cluster"},{"content":"Build your own personal slack bot in few steps. In this post we\u0026rsquo;ll navigate through process of creating the bot.\nSlack setup First create a slack workspace\n Give your workspace a name   create_workspace \nCreate a new bot at slack apps\n Give your new app a name Choose workspace you created before to install the app   create_app \nThen go to Features \u0026gt; OAuth \u0026amp; Permissions screen to scroll down to Bot Token Scopes to specify the OAuth scopes, select app_mentions and chat_write to enable the bot to send messages.\n add_oauth \nBefore jumping into application setup, let\u0026rsquo;s copy signing secret and verification token from basic information page. we\u0026rsquo;ll be using this later in our nodejs application\n secret_token \nApplication setup Create a npm project, install @slack/bolt and dotenv packages\nmkdir test-bot \u0026amp;\u0026amp; cd test-bot npm init -y npm i dotenv @slack/bolt -S Add start command to scripts if necessary\n... \u0026#34;scripts\u0026#34;: { \u0026#34;start\u0026#34;: \u0026#34;node index.js\u0026#34; } Create a .env file and add SLACK_SIGNING_SECRET, SLACK_BOT_TOKEN\nNote: Don\u0026rsquo;t commit this file to any repo\nSLACK_BOT_TOKEN= #token goes here SLACK_SIGNING_SECRET= #signing secret goes here In your index.js file, require the Bolt package, and initialize an app with credentials\nrequire(\u0026#34;dotenv\u0026#34;).config(); const { App } = require(\u0026#34;@slack/bolt\u0026#34;); const bot = new App({ signingSecret: process.env.SLACK_SIGNING_SECRET, token: process.env.SLACK_BOT_TOKEN, endpoints: \u0026#34;/slack/events\u0026#34;, }); (async () =\u0026gt; { // Start the app  await bot.start(process.env.PORT || 3000); console.log(\u0026#34;⚡️ Bolt app is running!\u0026#34;); })(); Deploy application to a live server like ngrok.\nEvent Setup We\u0026rsquo;ll need to subscribe to events, so that when a Slack event happens (like a user mentions app), app server will receive an event payload\n  Go to Event Subscriptions from the left-hand menu, and turn the toggle switch on to enable events\n  Enter your Request URL\n   enable_events \nSubscribe to app_mention event\n event_subscribe \nInstall app to workspace\n install_app_workspace \nYou should see bot in your workspace now!\nHandling Events To listen to any Events API events from Slack, use the event() method. This allows your app to take action when something happens in Slack. In this scenario, it\u0026rsquo;s triggered when a user mentions app.\nbot.event(\u0026#34;app_mention\u0026#34;, async ({ context, event }) =\u0026gt; { try { const command = event.text; let reply; if (command.includes(\u0026#34;Hi\u0026#34;)) { reply = `Hi \u0026lt;@${event.user}\u0026gt;, you mentioned me`; } else { reply = \u0026#34;How can i help you?\u0026#34;; } await bot.client.chat.postMessage({ token: context.botToken, channel: event.channel, text: `${reply}`, }); } catch (e) { console.log(`error responding ${e}`); } }); Okay, let\u0026rsquo;s try the app!\nAdd app to a channel and mention the app. You should see a response from bot!\nTroubleshooting Reinstall app if you don\u0026rsquo;t see any responses from bot\n reinstall_app \n","date":"2020-07-04T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/nodejs-slack-bot/","title":"Slack bot with Nodejs"},{"content":"Pi-hole is a fantastic tool that blocks DNS requests to ad servers. That means you can surf the web without having to look at ads on every page.\nPi-Hole in Kubernetes We are going to deploy modified version of this pihole helm chart\nLet\u0026rsquo;s start by cloning repo\ngit clone https://github.com/ChrisPhillips-cminion/pihole-helm.git cd pihole-helm We now need to make few updates to the chart\n Update ServerIP with container host IP Update image to v5.1.1 tag Add WEB_PASSWORD, TZ environment variables if needed Update values.yaml accordingly  spec:replicas:1template:metadata:labels:app:{{template \u0026#34;fullname\u0026#34; . }}spec:# hostNetwork: truehostAliases:- ip:127.0.0.1hostnames:- pi.holenodeSelector:kubernetes.io/hostname:randomstorecontainers:- name:{{.Chart.Name }}image:pihole/pihole:v5.1.1imagePullPolicy:{{.Values.image.pullPolicy }}stdin:truetty:trueresources:limits:memory:1Gienv:- name:\u0026#39;ServerIP\u0026#39;value:\u0026#39;192.168.1.132\u0026#39;- name:\u0026#39;DNS1\u0026#39;value:\u0026#39;8.8.8.8\u0026#39;- name:\u0026#39;DNS2\u0026#39;value:\u0026#39;8.8.4.4\u0026#39;- name:TZvalue:\u0026#34;America/New_York\u0026#34;- name:WEBPASSWORDvalue:\u0026#34;somepassword\u0026#34;#values.yamlconfigData:|-server=/local/192.168.1.1 address=/.vikaspogu.com/192.168.1.132ingress:host:pi-hole.vikaspogu.comInstall chart  Create a new namespace (optional) Install chart in namespace  kubectl create ns pi-hole helm install pi-hole .  Wait to pods  kubectl get pods NAME READY STATUS RESTARTS AGE pi-hole-pihole-5bb56b5bd-b2wl7 1/1 Running 0 61m  Navigate to ingress route in my case (pi-hole.vikaspogu.com) and login with WEBPASSWORD used in deployment   Pi-Hole UI \nDNS Server Configure Verizon FiOS router to use Pi Hole as the DNS server:\n  On the top navigation menu\n Click My Network    On the left menu list\n Click Network Connections    Click Broadband Connection (Ethernet/Coax)\u0026gt;Settings\n  Click the drop down for DNS Server and select \u0026lsquo;Use The Following DNS Server Addresses\u0026rsquo;\n  Type in the static IP Address of your pi (Or Pi-hole server)\n  Click Apply\n    ","date":"2020-03-07T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/pi-hole-kubernetes/","title":"Pi Hole on k3s cluster"},{"content":"Jenkins SSL Problem Recently, I encountered an issue while authenticating to OpenShift Jenkins using OpenShift OAuth plugin where trusted certificate provided by CA that aren\u0026rsquo;t included in the default JRE TrustStore.\n Jenkins Error \nLogs from Jenkins pod\n2020-02-10 21:19:07.335+0000 [id=17]\tINFO\to.o.j.p.o.OpenShiftOAuth2SecurityRealm#transportToUse: OpenShift OAuth got an SSL error when accessing the issuer\u0026#39;s token endpoint when using the SA certificate2020-02-10 21:19:07.348+0000 [id=17]\tINFO\to.o.j.p.o.OpenShiftOAuth2SecurityRealm#transportToUse: OpenShift OAuth provider token endpoint failed unexpectedly using the JVMs default keystore sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at java.base/sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:141) at java.base/sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:126) at java.base/java.security.cert.CertPathBuilder.build(CertPathBuilder.java:297) at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:434) Caused: sun.security.validator.ValidatorException: PKIX path building failed at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:439) at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:306) at java.base/sun.security.validator.Validator.validate(Validator.java:264) at java.base/sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:313) at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:222) at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:129) at java.base/sun.security.ssl.CertificateMessage$T12CertificateConsumer.checkServerCerts(CertificateMessage.java:629) Caused: javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at java.base/sun.security.ssl.Alert.createSSLException(Alert.java:131) at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:320) at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:263) Solution By default, Java Applications (as Jenkins) make use of the JVM TrustStore. If a Java Application needs to make use of a custom TrustStore, it needs to be configured to be able to do so.\nFirst, create a secret with JKS keystore and password.\noc create secret generic jenkins-https-jks --from-literal=https-jks-password=changeit \\ --from-file=custom-keystore.jks Mount jenkins-https-jks keystore secret as a volume to /var/jenkins_keystore location.\n...terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/lib/jenkinsname:jenkins-data- mountPath:/var/jenkins_keystorename:jenkins-https-keystoreserviceAccount:jenkinsserviceAccountName:jenkinsvolumes:- name:jenkins-datapersistentVolumeClaim:claimName:jenkins- name:jenkins-https-keystoresecret:defaultMode:420items:- key:custom-keystore.jkspath:custom-keystore.jkssecretName:jenkins-https-jks...Add the certificate to the Jenkins as startup parameters; Jenkins server can be configured to add following JAVA properties to JAVA_TOOL_OPTIONS environment variable.\n-Djavax.net.ssl.trustStore=/var/jenkins_keystore/custom-keystore.jks \\ -Djavax.net.ssl.trustStorePassword=changeit spec:containers:- env:- name:JENKINS_HTTPS_KEYSTORE_PASSWORDvalueFrom:secretKeyRef:key:https-jks-passwordname:jenkins-https-jks- name:JAVA_TOOL_OPTIONSvalue:-XX:+UnlockExperimentalVMOptions -Dsun.zip.disableMemoryMapping=true-Djavax.net.ssl.trustStore=/var/jenkins_keystore/custom-keystore.jks -Djavax.net.ssl.trustStorePassword=$(JENKINS_HTTPS_KEYSTORE_PASSWORD)Final deploymentconfig should look like this:\napiVersion:apps.OpenShift.io/v1kind:DeploymentConfigmetadata:annotations:template.alpha.OpenShift.io/wait-for-ready:\u0026#34;true\u0026#34;creationTimestamp:\u0026#34;2020-02-10T17:49:20Z\u0026#34;generation:10labels:app:jenkins-persistentname:jenkinsspec:replicas:1revisionHistoryLimit:10selector:name:jenkinsstrategy:activeDeadlineSeconds:21600recreateParams:timeoutSeconds:600resources:{}type:Recreatetemplate:metadata:creationTimestamp:nulllabels:name:jenkinsspec:containers:- env:- name:OpenShift_ENABLE_OAUTHvalue:\u0026#34;true\u0026#34;- name:OpenShift_ENABLE_REDIRECT_PROMPTvalue:\u0026#34;true\u0026#34;- name:DISABLE_ADMINISTRATIVE_MONITORSvalue:\u0026#34;false\u0026#34;- name:KUBERNETES_MASTERvalue:https://kubernetes.default:443- name:KUBERNETES_TRUST_CERTIFICATESvalue:\u0026#34;true\u0026#34;- name:JENKINS_SERVICE_NAMEvalue:jenkins- name:JNLP_SERVICE_NAMEvalue:jenkins-jnlp- name:ENABLE_FATAL_ERROR_LOG_FILEvalue:\u0026#34;false\u0026#34;- name:JENKINS_UC_INSECUREvalue:\u0026#34;false\u0026#34;- name:JENKINS_HTTPS_KEYSTORE_PASSWORDvalueFrom:secretKeyRef:key:https-jks-passwordname:jenkins-https-jks- name:JAVA_TOOL_OPTIONSvalue:-XX:+UnlockExperimentalVMOptions -Dsun.zip.disableMemoryMapping=true-Djavax.net.ssl.trustStore=/var/jenkins_keystore/custom-keystore.jks -Djavax.net.ssl.trustStorePassword=$(JENKINS_HTTPS_KEYSTORE_PASSWORD)image:image-registry.OpenShift-image-registry.svc:5000/OpenShift/jenkins@sha256:dd5f1c5d14a8a72aa4ca51224c26a661c2e4f19ea3e5f9b7d8343f4952de5f0dimagePullPolicy:IfNotPresentlivenessProbe:failureThreshold:2httpGet:path:/loginport:8080scheme:HTTPinitialDelaySeconds:420periodSeconds:360successThreshold:1timeoutSeconds:240name:jenkinsreadinessProbe:failureThreshold:3httpGet:path:/loginport:8080scheme:HTTPinitialDelaySeconds:3periodSeconds:10successThreshold:1timeoutSeconds:240resources:limits:memory:1GisecurityContext:capabilities:{}privileged:falseterminationMessagePath:/dev/termination-logterminationMessagePolicy:FilevolumeMounts:- mountPath:/var/lib/jenkinsname:jenkins-data- mountPath:/var/jenkins_keystorename:jenkins-https-keystorednsPolicy:ClusterFirstrestartPolicy:AlwaysschedulerName:default-schedulersecurityContext:{}serviceAccount:jenkinsserviceAccountName:jenkinsterminationGracePeriodSeconds:30volumes:- name:jenkins-datapersistentVolumeClaim:claimName:jenkins- name:jenkins-https-keystoresecret:defaultMode:420items:- key:custom-keystore.jkspath:custom-keystore.jkssecretName:jenkins-https-jkstest:falsetriggers:[]status:{}Start a new deployment.\noc rollout latest jenkins Once new pods are in running state, login will redirect to Jenkins home page.\n","date":"2020-02-10T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/openshift-jenkins-oauth-ssl/","title":"Jenkins OpenShift OAuth SSL"},{"content":"Installing podman as a remote client on macOS using vagrant. Vagrant setup is not covered in this post.\nPodman remote client Podman is the tool to start and manage containers. On macOS we have to use a thin remote-client that connects to a real Podman process running on a Linux host.\nHere are the main steps how to configure the remote-client to work with a Linux host:\n Create a linux machine using Vagrant Set key based ssh as root to the Linux host Install remote-client binary with Homebrew: brew cask install podman  Create a fedora vagrant box.\nmkdir fedora-box \u0026amp;\u0026amp; cd fedora-box echo \u0026#34;Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;generic/fedora30\u0026#34; config.vm.hostname = \u0026#34;fedora30\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |v| v.memory = 1024 v.cpus = 1 end end\u0026#34; \u0026gt;\u0026gt; Vagrantfile vagrant up \u0026amp;\u0026amp; vagrant ssh On macOS create new ssh keys and copy newly generated public key.\nssh-keygen cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3... Add ssh keys copied earlier on linux host to .ssh/authorized_keys.\necho \u0026#34;ssh-rsa AAAAB3...\u0026#34; \u0026gt;\u0026gt; /root/.ssh/authorized_keys On linux host install Podman and varlink socket. This is used by the remote-client to execute commands calling Podman’s API.\nsudo dnf --enablerepo=updates-testing install podman libvarlink-util libvarlink Install podman on macOS using homebrew\nbrew cask install podman Once podman is installed, create a connection parameters in $HOME/.config/containers/podman-remote.conf\ncat \u0026lt;\u0026lt;EOF \u0026gt;$HOME/.config/containers/podman-remote.conf [connections] [connections.host1] destination = \u0026#34;127.0.0.1\u0026#34; username = \u0026#34;root\u0026#34; default = true port = 2222 EOF # With the remoting file configured we can run podman simply as: podman images REPOSITORY TAG IMAGE ID CREATED SIZE Verify running a container:\npodman run --name tomcat -d docker.io/tomcat Trying to pull docker.io/tomcat... .... d2e6db3c7.... Building images:\nNote: The podman-remote.conf file seems to be ignored by the podman build command, so we have to add --remote-host 127.0.0.1 --username root --port 2222 to each command\npodman --remote-host 127.0.0.1 --username root --port 2222 build --tag mytag . ","date":"2020-01-06T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/podman-macos/","title":"Installing Podman remote client on macOS using vagrant"},{"content":"In my previous post, I went through k3s cluster home setup. Now, i\u0026rsquo;ll show how to measure the temperature of those Raspberry Pi\u0026rsquo;s using Telegraf, Influxdb, Grafana and Helm charts.\nWhy Telegraf? Telegraf has a plugin called exec, which can execute the commands on host machine at certain interval and parses those metrics from their output in any one of the accepted input data formats.\nFirst, deploy influxdb time series database chart\napiVersion:helm.cattle.io/v1kind:HelmChartmetadata:name:influxdbnamespace:kube-systemspec:chart:stable/influxdbtargetNamespace:monitoringGet Pi temperature I found this one liner /sys/class/thermal/thermal_zone0/temp which returns the temperature of the Pi; divide the output by 1000 to get a result in °C and use awk in order to have a float value.\nawk \u0026#39;{print $1/1000}\u0026#39; /sys/class/thermal/thermal_zone0/temp Update Chart values Update chart values, add [inputs.exec] to config and deploy it\napiVersion:helm.cattle.io/v1kind:HelmChartmetadata:name:telegrafnamespace:kube-systemspec:chart:stable/telegraftargetNamespace:monitoringvaluesContent:|-replicaCount: 2 image: repo: \u0026#34;telegraf\u0026#34; tag: \u0026#34;latest\u0026#34; pullPolicy: IfNotPresent env: - name: HOSTNAME valueFrom: fieldRef: fieldPath: spec.nodeName config: inputs: - exec: commands: [\u0026#34;awk \u0026#39;{print $1/1000}\u0026#39; /sys/class/thermal/thermal_zone0/temp\u0026#34;] name_override: \u0026#34;rpi_temp\u0026#34; data_format: \u0026#34;value\u0026#34; data_type: \u0026#34;float\u0026#34;Add Datasource Once influxdb and telegraf pods are in ready state, add influxdb datasource in grafana.\n Traefik UI \nGrafana For Grafana visualization, import this dashboard.\n Traefik UI \n","date":"2020-01-01T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/raspberry-pi-temp-telegraf/","title":"Measure Raspberry Pi temperature using Telegraf, Influxdb, Grafana on k3s"},{"content":"In this post, I’ll share my home lab setup for Rancher\u0026rsquo;s k3s kubernetes cluster.\nUse-case:\n A web interface to be accessible outside of my home so I could check and manage devices while away Way to manage dynamic DNS since I don’t have a static IP  Setup  Setting up a master + single node Kubernetes cluster Deploying DNS updater as a Kubernetes CronJob object Deploying Traefik as a Kubernetes Ingress Controller and configuring it to manage SSL with Let’s Encrypt  Setting up a Pi Kubernetes Cluster I followed an excellent guide written by Alex Ellis here to initialize a cluster on the master and then join a single node.\nk3s kubectl get nodes NAME STATUS ROLES AGE VERSION pi-node1 Ready \u0026lt;none\u0026gt; 3d v1.16.3-k3s.2 pi-master Ready master 3d v1.16.3-k3s.2 DNS and Routing  Add a DNS entry for the wildcard domain *.home.vikaspogu.com to point at the dynamic IP Open ports 80 and 443 on router’s firewall  At this point a short dig on domain should return your dynamic IP.\n$ dig +short test.home.vikaspogu.com X.X.X.X I found this script online which will update DNS record if Dynamic IP is changed.\n#!/bin/sh zone=example.com # dnsrecord is the A record which will be updated dnsrecord=www.example.com EMAIL=me@cloudflare.com API_KEY=1234567890abcdef1234567890abcdef # Get the current external IP address ip=$(dig +short \u0026lt;CURRENT EXTERNAL IP\u0026gt;) echo \u0026#34;Current IP is $ip\u0026#34; if host $dnsrecord 1.1.1.1 | grep \u0026#34;has address\u0026#34; | grep \u0026#34;$ip\u0026#34;; then echo \u0026#34;$dnsrecordis currently set to $ip; no changes needed\u0026#34; exit fi # if here, the dns record needs updating # get the zone id for the requested zone zoneid=$(curl -s -X GET \u0026#34;https://api.cloudflare.com/client/v4/zones?name=$zone\u0026amp;status=active\u0026#34; \\  -H \u0026#34;X-Auth-Email: $EMAIL\u0026#34; \\  -H \u0026#34;X-Auth-Key: $API_KEY\u0026#34; \\  -H \u0026#34;Content-Type: application/json\u0026#34; | jq -r \u0026#39;{\u0026#34;result\u0026#34;}[] | .[0] | .id\u0026#39;) echo \u0026#34;Zoneid for $zoneis $zoneid\u0026#34; # get the dns record id dnsrecordid=$(curl -s -X GET \u0026#34;https://api.cloudflare.com/client/v4/zones/$zoneid/dns_records?type=A\u0026amp;name=$dnsrecord\u0026#34; \\  -H \u0026#34;X-Auth-Email: $EMAIL\u0026#34; \\  -H \u0026#34;X-Auth-Key: $API_KEY\u0026#34; \\  -H \u0026#34;Content-Type: application/json\u0026#34; | jq -r \u0026#39;{\u0026#34;result\u0026#34;}[] | .[0] | .id\u0026#39;) echo \u0026#34;DNSrecordid for $dnsrecordis $dnsrecordid\u0026#34; # update the record curl -s -X PUT \u0026#34;https://api.cloudflare.com/client/v4/zones/$zoneid/dns_records/$dnsrecordid\u0026#34; \\  -H \u0026#34;X-Auth-Email: $EMAIL\u0026#34; \\  -H \u0026#34;X-Auth-Key: $API_KEY\u0026#34; \\  -H \u0026#34;Content-Type: application/json\u0026#34; \\  --data \u0026#34;{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;A\\\u0026#34;,\\\u0026#34;name\\\u0026#34;:\\\u0026#34;$dnsrecord\\\u0026#34;,\\\u0026#34;content\\\u0026#34;:\\\u0026#34;$ip\\\u0026#34;,\\\u0026#34;ttl\\\u0026#34;:1,\\\u0026#34;proxied\\\u0026#34;:false}\u0026#34; | jq Create a configmap from script, secret with cloudflare EMAIL and GLOBAL_API_TOKEN.\n$ k3s create configmap update-script --from-file=cloudfare-dns-update.sh $ k3s kubectl create secret generic cloudflare --from-literal=email=me@cloudflare.com \\ --from-literal=api_key=1234567890abcdef1234567890abcdef Now create a kubernetes cronjob to update DNS record to right address.\napiVersion:batch/v1beta1kind:CronJobmetadata:name:dns-updatenamespace:defaultspec:schedule:\u0026#34;0 0 * * *\u0026#34;concurrencyPolicy:ForbidjobTemplate:spec:template:spec:restartPolicy:OnFailurecontainers:- name:dns-updateimage:e2eteam/dnsutils:1.1-linux-armcommand:[\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;/scripts/cloudfare-dns-update.sh\u0026#34;]env:- name:API_KEYvalueFrom:secretKeyRef:name:cloudflarekey:api_key- name:EMAILvalueFrom:secretKeyRef:name:cloudflarekey:emailvolumeMounts:- name:config-volumemountPath:/scriptsvolumes:- name:config-volumeconfigMap:name:update-scriptdefaultMode:0744Traefik and Let’s Encrypt With a functioning cluster and the networking setup complete, the next task is to deploy a reverse proxy to manage the application routing.\nIn Kubernetes we can deploy an Ingress Controller to achieve this. An Ingress Controller is an implementation of a reverse proxy which listens for changes to KubernetesIngress resources and updates it’s configuration accordingly.\nTraefik provides an detailed instructions on kubernetes implementation but I customized it slightly to get things working with my setup.\nFirst create RoleBinding\u0026rsquo;s.\nk3s kubectl apply -f https://raw.githubusercontent.com/containous/traefik/v1.7/examples/k8s/traefik-rbac.yaml Configure Let’s Encrypt to support HTTPS endpoint and automatically fetch certificates. I used Cloudflare as the DNS provider which configures Traefik to use DNS records for domain validation.\n[acme]email = \u0026#34;me@cloudflare.com\u0026#34;storage=\u0026#34;./acme.json\u0026#34;entryPoint = \u0026#34;https\u0026#34;acmeLogging=true[acme.dnsChallenge]provider = \u0026#34;cloudflare\u0026#34;delayBeforeCheck = 0[[acme.domains]]main = \u0026#34;*.home.vikaspogu.com\u0026#34;sans = [\u0026#34;home.vikaspogu.com\u0026#34;]The Deployment objects look like this:\napiVersion:v1data:traefik.toml:|# traefik.toml logLevel = \u0026#34;info\u0026#34; debug = true insecureSkipVerify = true defaultEntryPoints = [\u0026#34;http\u0026#34;,\u0026#34;https\u0026#34;] [entryPoints] [entryPoints.http] address = \u0026#34;:80\u0026#34; [entryPoints.http.redirect] entryPoint = \u0026#34;https\u0026#34; [entryPoints.https] address = \u0026#34;:443\u0026#34; [entryPoints.https.tls] [api] dashboard = true [kubernetes] [acme] email = \u0026#34;me@cloudflare.com\u0026#34; storage=\u0026#34;./acme.json\u0026#34; entryPoint = \u0026#34;https\u0026#34; acmeLogging=true [acme.dnsChallenge] provider = \u0026#34;cloudflare\u0026#34; delayBeforeCheck = 0 [[acme.domains]] main = \u0026#34;*.home.vikaspogu.com\u0026#34; sans = [\u0026#34;home.vikaspogu.com\u0026#34;]kind:ConfigMapmetadata:labels:app:traefikname:traefik-confignamespace:default---apiVersion:v1kind:ServiceAccountmetadata:namespace:defaultname:traefik-ingress-controllerlabels:app:traefik---kind:DeploymentapiVersion:apps/v1metadata:namespace:defaultname:traefiklabels:app:traefikspec:replicas:1selector:matchLabels:app:traefiktemplate:metadata:labels:app:traefikspec:serviceAccountName:traefik-ingress-controllercontainers:- name:traefikimage:traefik:1.7.4ports:- name:httpcontainerPort:80- name:httpscontainerPort:443- name:admincontainerPort:8080env:- name:CF_API_EMAILvalueFrom:secretKeyRef:name:cloudflarekey:email- name:CF_API_KEYvalueFrom:secretKeyRef:name:cloudflarekey:api_keyvolumeMounts:- mountPath:\u0026#34;/config\u0026#34;name:\u0026#34;config\u0026#34;args:- --configfile=/config/traefik.tomlvolumes:- name:configconfigMap:name:traefik-config---kind:ServiceapiVersion:v1metadata:name:traefik-ingress-servicenamespace:defaultspec:selector:app:traefikports:- protocol:TCPport:80name:http- protocol:TCPport:443name:https- protocol:TCPport:8080name:adminexternalIPs:- 192.168.0.101# This is the node addressDeploy Ingress controller for traefik dashboard.\n---apiVersion:extensions/v1beta1kind:Ingressmetadata:name:traefik-web-uinamespace:defaultspec:rules:- host:traefik.home.vikaspogu.comhttp:paths:- path:/backend:serviceName:traefik-ingress-serviceservicePort:adminVoila!\n Traefik UI \nDeploy kubernetes dashboard Follow these instructions to deploy dashboard UI.\nCreate ingress controller to access dashboard.\n---apiVersion:extensions/v1beta1kind:Ingressmetadata:name:kubernetes-dashboard-ingressnamespace:kubernetes-dashboardspec:rules:- host:kubernetes-dashboard.home.vikaspogu.comhttp:paths:- backend:serviceName:kubernetes-dashboardservicePort:443","date":"2019-12-31T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/kubernetes-home-cluster-traefik/","title":"k3s cluster with Raspberry-Pi, Traefik"},{"content":"Recently, i ran into a issue where pushing images to the docker registry after a build fails\nPushing image docker-registry.default.svc:5000/simple-go-build/simple-go:latest ... Registry server Address: Registry server User Name: serviceaccount Registry server Email: serviceaccount@example.org Registry server Password: \u0026lt;\u0026lt;non-empty\u0026gt;\u0026gt; error: build error: Failed to push image: received unexpected HTTP status: 500 Internal Server Error Registry pods logs show permission denied\nerr.code=UNKNOWN err.detail=\u0026#34;filesystem: mkdir /registry/docker/registry/v2/repositories/simple-go-build/simple-go/_uploads/c34415b4-c6d8-42ba-9854-aee449efd984: permission denied\u0026#34; One of the Red Hat solutions article suggested to verify the file ownership of the files, directories in the volume and compare it to the uid of the registry\nChanging the owner recursively to the uid of the registry, fixed the issue\nroot@master# chown -R 1001 /exports/registry/docker/ ","date":"2019-12-18T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/ocp-docker-registry-500-err/","title":"Permission denied pushing to OpenShift Registry"},{"content":"This is short post on adding basic authentication to go applications. Our sample application uses gin web framework\nLet\u0026rsquo;s start by creating a gin router with default middleware, by default it serves on :8080 unless a PORT environment variable was defined\nfunc main(){ r := gin.Default() r.GET(\u0026#34;/getAllUsers\u0026#34;, basicAuth, handlers.UsersList) _ = r.Run() } Now that we have our basic route, lets create a method to add authentication logic. Get basic auth credentials from context request and validate them. If user isn\u0026rsquo;t authenticated, authentication window is prompted with username and password.\nfunc basicAuth(c *gin.Context) { // Get the Basic Authentication credentials \tuser, password, hasAuth := c.Request.BasicAuth() if hasAuth \u0026amp;\u0026amp; user == \u0026#34;testuser\u0026#34; \u0026amp;\u0026amp; password == \u0026#34;testpass\u0026#34; { log.WithFields(log.Fields{ \u0026#34;user\u0026#34;: user, }).Info(\u0026#34;User authenticated\u0026#34;) } else { c.Abort() c.Writer.Header().Set(\u0026#34;WWW-Authenticate\u0026#34;, \u0026#34;Basic realm=Restricted\u0026#34;) return } } Run application\ngo run main.go Verify if authentication works\ncurl -X GET \u0026#34;http://testuser:testpass@localhost:8080/getAllUsers\u0026#34; ","date":"2019-12-16T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/golang-basicauth-gin/","title":"Basic Authentication in Go with Gin"},{"content":"Set up NFS shares that will serve as storage domains on a Red Hat Enterprise Linux server.\nAdd firewall rule are to rhel server\nfirewall-cmd --permanent --add-service nfs firewall-cmd --permanent --add-service mountd firewall-cmd --reload Create and add group kvm; set the ownership of your exported directories to 36:36, which gives vdsm:kvm ownership; change the mode of the directories so that read and write access is granted to the owner\ngroupadd kvm -g 36 useradd vdsm -u 36 -g 36 mkdir -pv /home/rhv-data-vol chown -R 36:36 /home/rhv-data-vol chmod 0755 /home/rhv-data-vol Add newly created directory to /etc/exports file which controls file systems are exported to remote hosts and specifies options.\necho \u0026#34;/home/rhv-data-vol 192.168.10.1(rw,sync)\u0026#34; \u0026gt;\u0026gt; /etc/exports exportfs -av Start, enable NFS server; check list of export server using showmount\nsystemctl start nfs systemctl enable nfs systemctl status nfs showmount -e ","date":"2019-11-02T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/create-nfs-server-rhel-rhv/","title":"Create and add NFS storage to RHV"},{"content":"Couchbase SSL If you have followed dynamic creation of java keystores in OpenShift post and wondered how to use similar concepts for couchbase database and a java application. This post will help you.\nCouchbase setup This is the couchbase documentation for configuring server side certificates, we are interested in last few steps since OpenShift will generate key and cert by adding annotation to the couchbase service.\nNote: By adding this annotation you can dynamically create certificates service.alpha.OpenShift.io/serving-cert-secret-name: couchbase-db-certs\ncouchbase service looks like this:\napiVersion:v1kind:Servicemetadata:annotations:kubectl.kubernetes.io/last-applied-configuration:\u0026#34;\u0026#34;service.alpha.OpenShift.io/serving-cert-secret-name:couchbase-db-certslabels:component:couchbase-dbname:couchbase-dbnamespace:myprojectspec:ports:- name:consolerestport:8091protocol:TCPtargetPort:8091To convert certificates as couchbase expects, we are going to use an init container.\nWe will use an emptyDir volume to store cert and key in /opt/couchbase/var/lib/couchbase/inbox/ location so that couchbase can access them.\nInit container will run sequence of commands to split certificate, place them into /opt/couchbase/var/lib/couchbase/inbox/ location and name cert file as chain.pem, key as pkey.key.\ninit container will look as follows:\ninitContainers:- args:- \u0026#34;-c\u0026#34;- \u0026gt;-csplit -z -f crt- $crtfile \u0026#39;/-----BEGIN CERTIFICATE-----/\u0026#39; \u0026#39;{*}\u0026#39; \u0026amp;\u0026amp; for file in crt-*; do cat $file \u0026gt; /opt/couchbase/var/lib/couchbase/inbox/service-$file; done \u0026amp;\u0026amp; cat $crtfile \u0026gt; /opt/couchbase/var/lib/couchbase/inbox/chain.pem \u0026amp;\u0026amp; cat $keyfile \u0026gt; /opt/couchbase/var/lib/couchbase/inbox/pkey.keycommand:- /bin/bashenv:- name:keyfilevalue:/var/run/secrets/OpenShift.io/services_serving_certs/tls.key- name:crtfilevalue:/var/run/secrets/OpenShift.io/services_serving_certs/tls.crt- name:passwordvalue:changeitimage:registry.access.redhat.com/redhat-sso-7/sso72-OpenShift:latestimagePullPolicy:Alwaysname:couchbase-sslvolumeMounts:- mountPath:/var/run/secrets/OpenShift.io/services_serving_certsname:couchbase-db-certs- mountPath:/opt/couchbase/var/lib/couchbase/inbox/name:couchbase-ssl-volumevolumes:- emptyDir:{}name:couchbase-ssl-volume- name:couchbase-db-certssecret:defaultMode:420secretName:couchbase-db-certsNext add couchbase-ssl-volume emptyDir volume mount to actual container so file can be access by couchbase.\nspec:containers:- env:...volumeMounts:- mountPath:/opt/couchbase/var/lib/couchbase/inbox/name:couchbase-ssl-volumeI am using a rhel7-couchbase image, on startup it runs a initialization script to setup cluster; at that time we will upload the certificate, and activate it using these commands.\ncouchbase-cli ssl-manage -c http://localhost:8091 -u Administrator \\ -p password --upload-cluster-ca=${SERVICE_CERT} couchbase-cli ssl-manage -c http://localhost:8091 -u Administrator \\ -p password --set-node-certificate Pass the cert location as environment variable SERVICE_CERT in deployment config.\n- env:- name:SERVICE_CERTvalue:/opt/couchbase/var/lib/couchbase/inbox/service-crt-01Verify logs on container\nSUCCESS: Uploaded cluster certificate to http://localhost:8091 SUCCESS: Node certificate set We can also verify in couchbase UI\n Couchbase UI \nAt this point couchbase setup is done.\nApplication setup We will be using same steps as SSL client from dynamically-creating-java-keystores-OpenShift post\nTo make a secure connection to the couchbase, it will need the trust store generated by the pem-to-truststore initContainer. Here is the client’s app deployment config:\n- apiVersion:v1kind:DeploymentConfigmetadata:labels:app:ssl-clientname:ssl-clientspec:replicas:1selector:deploymentconfig:ssl-clienttemplate:metadata:labels:app:ssl-clientdeploymentconfig:ssl-clientspec:containers:- name:ssl-clientimage:ssl-clientimagePullPolicy:Alwaysenv:- name:JAVA_OPTIONSvalue:-Djavax.net.ssl.trustStore=/var/run/secrets/java.io/keystores/truststore.jks -Djavax.net.ssl.trustStorePassword=changeit- name:POD_NAMESPACEvalueFrom:fieldRef:apiVersion:v1fieldPath:metadata.namespacevolumeMounts:- mountPath:/var/run/secrets/java.io/keystoresname:keystore-volumeinitContainers:- name:pem-to-truststoreimage:registry.access.redhat.com/redhat-sso-7/sso71-OpenShift:1.1-16env:- name:ca_bundlevalue:/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt- name:truststore_jksvalue:/var/run/secrets/java.io/keystores/truststore.jks- name:passwordvalue:changeitcommand:[\u0026#34;/bin/bash\u0026#34;]args:[\u0026#34;-c\u0026#34;,\u0026#34;csplit -z -f crt- $ca_bundle \u0026#39;/-----BEGIN CERTIFICATE-----/\u0026#39; \u0026#39;{*}\u0026#39; \u0026amp;\u0026amp; for file in crt-*; do keytool -import -noprompt -keystore $truststore_jks -file $file -storepass changeit -alias service-$file; done\u0026#34;,]volumeMounts:- mountPath:/var/run/secrets/java.io/keystoresname:keystore-volumevolumes:- emtpyDir:{}name:keystore-volumeThe next step is to enable encryption and pass the path and password of the truststore generated by the initContainer\nCouchbaseEnvironment env = DefaultCouchbaseEnvironment.builder().sslEnabled(true) .sslTruststoreFile(\u0026#34;/var/run/secrets/java.io/keystores/truststore.jks\u0026#34;) .sslTruststorePassword(\u0026#34;changeit\u0026#34;).build(); cachedCluster = CouchbaseCluster.create(env, \u0026#34;couchbase-db\u0026#34;) .authenticate(\u0026#34;Administrator\u0026#34;, \u0026#34;password\u0026#34;); Deploy your application, if successful you should see similar output in container logs\n2019-08-28 15:33:27.952 INFO 1 --- [cTaskExecutor-1] com.couchbase.client.core.CouchbaseCore : CouchbaseEnvironment: {sslEnabled=true, sslKeystoreFile=\u0026#39;null\u0026#39;, sslTruststoreFile=\u0026#39;/var/run/secrets/java.io/keystores/truststore.jks\u0026#39;, sslKeystorePassword=false, sslTruststorePassword=true, sslKeystore=null, sslTruststore=null, bootstrapHttpEnabled=true, bootstrapCarrierEnabled=true, bootstrapHttpDirectPort=8091, ... ","date":"2019-08-28T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/couchbase-ssl-openshift/","title":"Configuring couchbase SSL for dynamic certificates in OpenShift"},{"content":"Recently I came across tektoncd project, The Tekton Pipelines project provides Kubernetes-style resources for declaring CI/CD-style pipelines caught my attention and started playing with it.\nBasic Concepts  tekton concepts \nIn order to create a tekton pipeline, one does the following:\n Create custom or install existing reusable Tasks Create a Pipeline and PipelineResources to define your application\u0026rsquo;s delivery pipeline Create a PipelineRun to instantiate and invoke the pipeline  Installing Tekton on OpenShift Login as a user with cluster-admin privileges\noc new-project tekton-pipelines oc adm policy add-scc-to-user anyuid -z tekton-pipelines-controller oc apply --filename https://storage.googleapis.com/tekton-releases/latest/release.yaml Install dashboard Dashboard is a general purpose, web-based UI for Tekton Pipelines. Tekton also has cli client\ncurl -L https://github.com/tektoncd/dashboard/releases/download/v0/gcr-tekton-dashboard.yaml | oc apply -f - Expose tekton-dashboard service as a route\noc expose service tekton-dashboard \\  -n tekton-pipelines \\  --name \u0026#34;tekton-dashboard\u0026#34; \\  --port=\u0026#34;http\u0026#34;  tekton dashboard \nCreate pipeline This pipeline builds image from the source, starts a new rollout\nCreate a new project\noc new-project tektontutorial Create a service account for running pipelines and enable it to run privileged pods for building images\noc create serviceaccount pipeline oc adm policy add-scc-to-user privileged -z pipeline oc adm policy add-role-to-user edit -z pipeline Optionally, create OpenShift objects(i.e DeploymentConfig, ImageStream, Service, Route)\n---apiVersion:image.OpenShift.io/v1kind:ImageStreammetadata:labels:app:go-samplename:go-sample---apiVersion:apps.OpenShift.io/v1kind:DeploymentConfigmetadata:labels:app:go-samplename:go-samplespec:replicas:1revisionHistoryLimit:10selector:app:go-sampledeploymentconfig:go-samplestrategy:activeDeadlineSeconds:21600resources:{}rollingParams:intervalSeconds:1maxSurge:25%maxUnavailable:25%timeoutSeconds:600updatePeriodSeconds:1type:Rollingtemplate:metadata:labels:app:go-sampledeploymentconfig:go-samplespec:containers:- image:go-sample:latestimagePullPolicy:AlwayslivenessProbe:failureThreshold:3httpGet:path:/port:8080scheme:HTTPinitialDelaySeconds:45periodSeconds:10successThreshold:1timeoutSeconds:1name:go-sampleports:- containerPort:8080protocol:TCPreadinessProbe:failureThreshold:3httpGet:path:/port:8080scheme:HTTPinitialDelaySeconds:45periodSeconds:10successThreshold:1timeoutSeconds:5resources:{}terminationMessagePath:/dev/termination-logterminationMessagePolicy:FilednsPolicy:ClusterFirstrestartPolicy:AlwaysschedulerName:default-schedulersecurityContext:{}terminationGracePeriodSeconds:30test:falsetriggers:- imageChangeParams:containerNames:- go-samplefrom:kind:ImageStreamTagname:go-sample:latestnamespace:tektontutorialtype:ImageChange- type:ConfigChange---apiVersion:v1kind:Servicemetadata:labels:app:go-samplename:go-samplespec:ports:- name:8080-tcpport:8080protocol:TCPtargetPort:8080selector:app:go-sampledeploymentconfig:go-samplesessionAffinity:Nonetype:ClusterIP---apiVersion:route.OpenShift.io/v1kind:Routemetadata:labels:app:go-samplename:go-samplespec:port:targetPort:8080-tcpto:kind:Servicename:go-sampleweight:100oc apply -f go-sample-template.yml Deployment will not complete since there are no container image for go-sample app\n App template \nCreate a s2i-go, OpenShift-cli task. You can find more examples of reusable tasks in the Tekton Catalog and OpenShift Catalog repositories.\nNote: Tasks consist of a number of steps that are executed sequentially. Each task is executed in a separate container within the same pod\noc apply -f https://raw.githubusercontent.com/OpenShift/pipelines-catalog/master/s2i-go/s2i-go-task.yaml oc create -f https://raw.githubusercontent.com/tektoncd/catalog/master/OpenShift-client/OpenShift-client-task.yaml Create pipeline resources\n---apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:go-sample-imagespec:type:imageparams:- name:urlvalue:image-registry.OpenShift-image-registry.svc:5000/tektontutorial/go-sample---apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:go-sample-gitspec:type:gitparams:- name:urlvalue:https://github.com/go-training/helloworldoc apply -f resources.yml  Pipeline resources \nCreate pipeline, pipelines has two tasks here build, deploy. Build uses s2i-go task to create image from source and deploy uses OpenShift-client task to rollout latest deployment of go-sample\napiVersion:tekton.dev/v1alpha1kind:Pipelinemetadata:name:go-sample-pipelinespec:resources:- name:app-gittype:git- name:app-imagetype:imagetasks:- name:buildtaskRef:name:s2i-gokind:Taskparams:- name:TLSVERIFYvalue:\u0026#34;false\u0026#34;resources:inputs:- name:sourceresource:app-gitoutputs:- name:imageresource:app-image- name:deploytaskRef:name:OpenShift-clientkind:ClusterTaskrunAfter:- buildparams:- name:ARGSvalue:\u0026#34;rollout latest go-sample\u0026#34;oc apply -f go-sample-pipeline.yml  Pipeline \nStart pipeline on dashboard or by tektoncli\ntkn pipeline start go-sample-pipeline \\  -r app-git=go-sample-git -r app-image=go-sample-image \\  -s pipeline  PipelineRun \nClick on Create PipelineRun, select pipeline, resources, service account and start the pipeline\n Pipeline start \nOnce, finished you should see all tasks marked in green\n App template \ngo-sample deployment should have 1 running pod\n","date":"2019-08-09T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/intro-tektoncd-ocp/","title":"TektonCD on OpenShift"},{"content":"Recently I was working on a React project with Go backend using Gin web framework. Keycloak was the authentication mechanism for the frontend; I also wanted to secure the backend using JSON Web Tokens which was provided by Keycloak on every login. Setup for jwt verification in Go was easy.\nFirst, copy RS256 algorithm public key value from Keycloak\n sso_setup \nSend the token as Authorization header\naxios .get(BACKEND_URL.concat(\u0026#34;sampleendpoint\u0026#34;), { headers: { Authorization: this.state.token } }) .then(res =\u0026gt; {}); Now Go-backend setup; let\u0026rsquo;s install the jwt-go, gin-cors libraries:\ngo get -u github.com/dgrijalva/jwt-go $ go get -u github.com/gin-contrib/cors Add cors config to the router to allow authorization header\nrouter.Use(cors.New(cors.Config{ AllowOrigins: []string{\u0026#34;*\u0026#34;}, AllowMethods: []string{\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;HEAD\u0026#34;}, AllowHeaders: []string{\u0026#34;Origin\u0026#34;, \u0026#34;content-type\u0026#34;, \u0026#34;accept\u0026#34;, \u0026#34;authorization\u0026#34;}, ExposeHeaders: []string{\u0026#34;Content-Length\u0026#34;}, AllowCredentials: true, MaxAge: 12 * time.Hour, })) Let\u0026rsquo;s create a custom handler; add the public key from Keycloak and pass it to ParseRSAPublicKeyFromPEM which will return a key. The key and token are then validated\nfunc VerifyToken(c *gin.Context) { SecretKey := \u0026#34;-----BEGIN CERTIFICATE-----\\n\u0026#34;+ \u0026#34;MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEApn ...... +wnyuCHaCHp8P1yCnwIDAQAB\u0026#34; + \u0026#34;\\n-----END CERTIFICATE-----\u0026#34; reqToken := c.GetHeader(\u0026#34;Authorization\u0026#34;) key, er := jwt.ParseRSAPublicKeyFromPEM([]byte(SecretKey)) if er != nil { fmt.Println(er) c.Abort() c.Writer.WriteHeader(http.StatusUnauthorized) c.Writer.Write([]byte(\u0026#34;Unauthorized\u0026#34;)) return } token, err := jwt.Parse(reqToken, func(token *jwt.Token) (interface{}, error) { // Don\u0026#39;t forget to validate the alg is what you expect: \tif _, ok := token.Method.(*jwt.SigningMethodRSA); !ok { return nil, fmt.Errorf(\u0026#34;Unexpected signing method: %v\u0026#34;, token.Header[\u0026#34;alg\u0026#34;]) } return key, nil }) if err != nil { fmt.Println(err) c.Abort() c.Writer.WriteHeader(http.StatusUnauthorized) c.Writer.Write([]byte(\u0026#34;Unauthorized\u0026#34;)) return } if _, ok := token.Claims.(jwt.MapClaims); ok \u0026amp;\u0026amp; token.Valid { fmt.Println(\u0026#34;token is valid\u0026#34;) } } Add the handler to the route\nrouter.GET(\u0026#34;/sample\u0026#34;, VerifyToken(), handlers.SampleEndpoint) That\u0026rsquo;s, it done, If the token is valid, you will get the data from backend or else you\u0026rsquo;ll see 401 Unauthorized\n","date":"2019-07-27T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/sso-jwt-golang/","title":"Go JWT Authentication with keycloak"},{"content":"In this post, I will show you how to secure a React app using RedHat SSO (upstream keycloak). In this case, openid-connect is my identity provider.\n sso_setup \nInstall the official keycloak js adapter\nnpm i keycloak-js --save Setup the client with the host and port; in my case it\u0026rsquo;s localhost:9000\n sso_setup \nIn App.js add in a JavaScript object with the required configuration; you will find these configurations under Clients-\u0026gt;Installation\n//keycloak init options const initOptions = { url: \u0026#34;https://localhost:8080/auth\u0026#34;, realm: \u0026#34;test\u0026#34;, clientId: \u0026#34;react-app\u0026#34;, onLoad: \u0026#34;login-required\u0026#34; };  sso_setup \nBy default, to authenticate you need to call the login function. However, there are two options available to make the adapter automatically authenticate. You can pass login-required or check-sso to the init function. login-required will authenticate the client if the user is logged-in to {project_name} or display the login page if not. check-sso will only authenticate the client if the user is already logged-in; if the user is not logged-in the browser will be redirected back to the application and remain unauthenticated.\ncomponentDidMount() { let keycloak = Keycloak(initOptions); keycloak.init({ onLoad: initOptions.onLoad }).success(authenticated =\u0026gt; {}); } Finally\nimport * as Keycloak from \u0026#34;keycloak-js\u0026#34;; //keycloak init options const initOptions = { url: \u0026#34;https://localhost:8080/auth\u0026#34;, realm: \u0026#34;test\u0026#34;, clientId: \u0026#34;react-app\u0026#34;, onLoad: \u0026#34;login-required\u0026#34; }; class App extends React.Component { constructor(props) { super(props); this.state = { keycloak: null, authenticated: false }; } componentDidMount() { let keycloak = Keycloak(initOptions); keycloak.init({ onLoad: initOptions.onLoad }).success(authenticated =\u0026gt; { this.setState({ keycloak: keycloak, authenticated: authenticated }); }); } render() { const { keycloak, authenticated } = this.state; if (keycloak) { if (authenticated) { return ( \u0026lt;React.Fragment\u0026gt; \u0026lt;AppRouter /\u0026gt; \u0026lt;/React.Fragment\u0026gt; ); } } return \u0026lt;div\u0026gt;Initializing SS0...\u0026lt;/div\u0026gt;; } } Run your app\n$ npm run start Navigate to http://localhost:9000; you should see the login page if you are not authenticated\n","date":"2019-07-25T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/redhat-sso-react/","title":"React App with RedHat SSO or keycloak"},{"content":"Recently I encountered an JWT token expired error on heketi pod in OpenShift cluster.\n[jwt] ERROR 2019/07/16 19:17:14 heketi/middleware/jwt.go:66:middleware.(*HeketiJwtClaims).Valid: exp validation failed: Token is expired by 1h48m59s After a lot of google search, I synchronized clocks across the pod running heketi and the masters, which solved the issue\nntpdate -q 0.rhel.pool.ntp.org; systemctl restart ntpd ","date":"2019-07-16T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/heketi-jwt-error/","title":"Heketi JWT token expired error"},{"content":"To order to integrate Patternfly framework into a ReactJS application, create a new project or use an existing one\nnpx create-react-app patternfly-setup-react Install patternfly dependencies react-core, react-table and patternfly\nnpm i --save @patternfly/patternfly \\  @patternfly/react-core @patternfly/react-table Note: Import base.css and patternfly.css in your project, or some components may diverge in appearance\n//This imports are must to render css import \u0026#34;@patternfly/react-core/dist/styles/base.css\u0026#34;; import \u0026#34;@patternfly/patternfly/patternfly.css\u0026#34;; To make sure everything is working correctly, update App.js with a demo layout from documentation\nimport React from \u0026#34;react\u0026#34;; import { Avatar, Brand, Button, ButtonVariant ... ... } from \u0026#34;@patternfly/react-core\u0026#34;; import accessibleStyles from \u0026#34;@patternfly/react-styles/css/utilities/Accessibility/accessibility\u0026#34;; import spacingStyles from \u0026#34;@patternfly/react-styles/css/utilities/Spacing/spacing\u0026#34;; import { css } from \u0026#34;@patternfly/react-styles\u0026#34;; import { BellIcon, CogIcon } from \u0026#34;@patternfly/react-icons\u0026#34;; //This imports are must to render css import \u0026#34;@patternfly/react-core/dist/styles/base.css\u0026#34;; import \u0026#34;@patternfly/patternfly/patternfly.css\u0026#34;; class App extends React.Component { ... ... return ( \u0026lt;React.Fragment\u0026gt; \u0026lt;Page header={Header} sidebar={Sidebar} isManagedSidebar skipToContent={PageSkipToContent} \u0026gt; \u0026lt;PageSection variant={PageSectionVariants.light}\u0026gt; \u0026lt;TextContent\u0026gt; \u0026lt;Text component=\u0026#34;h1\u0026#34;\u0026gt;Main Title\u0026lt;/Text\u0026gt; \u0026lt;Text component=\u0026#34;p\u0026#34;\u0026gt; Body text should be Overpass Regular at 16px. It should have leading of 24px because \u0026lt;br /\u0026gt; of it’s relative line height of 1.5. \u0026lt;/Text\u0026gt; \u0026lt;/TextContent\u0026gt; \u0026lt;/PageSection\u0026gt; \u0026lt;PageSection\u0026gt; \u0026lt;Gallery gutter=\u0026#34;md\u0026#34;\u0026gt; {Array.apply(0, Array(10)).map((x, i) =\u0026gt; ( \u0026lt;GalleryItem key={i}\u0026gt; \u0026lt;Card\u0026gt; \u0026lt;CardBody\u0026gt;This is a card\u0026lt;/CardBody\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/GalleryItem\u0026gt; ))} \u0026lt;/Gallery\u0026gt; \u0026lt;/PageSection\u0026gt; \u0026lt;/Page\u0026gt; \u0026lt;/React.Fragment\u0026gt; ); } } export default App; Start the application\nnpm start You should see patternfly design like this!\n intellij-debug \n","date":"2019-07-01T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/patternfly-setup-react/","title":"Patternfly setup in React Application"},{"content":"This post demonstrates how to authenticate a user against LDAP.\nLet\u0026rsquo;s start by installing basic-auth and ldapauth-fork packages\nnpm install ldapauth-fork npm install basic-auth Steps for implementation;\n Add packages Create a ldap variable with authentication configuration Basic auth should prompt for you username and password. Once user is found, verify the given password by trying to bind the user client with the found LDAP user object and given password.  const auth = require(\u0026#34;basic-auth\u0026#34;); var LdapAuth = require(\u0026#34;ldapauth-fork\u0026#34;); var ldap = new LdapAuth({ url: \u0026#34;ldap://ldap-url:389\u0026#34;, bindDN: \u0026#34;uid=rc,ou=AppAccounts,ou=People,ou=Entsys,dc=example.com\u0026#34;, bindCredentials: \u0026#34;credentials\u0026#34;, searchBase: \u0026#34;ou=entsys,dc=example.com\u0026#34;, searchFilter: \u0026#34;(uid={{username}})\u0026#34;, reconnect: true }); app.use(\u0026#34;/api/admin/\u0026#34;, (req, res, next) =\u0026gt; { const credentials = auth(req); if (credentials) { ldap.authenticate(credentials.name, credentials.pass, function(err, user) { if (err) { console.log(err.message); return res .status(\u0026#34;401\u0026#34;) .set({ \u0026#34;WWW-Authenticate\u0026#34;: \u0026#39;Basic realm=\u0026#34;Access Denied\u0026#34;\u0026#39; }) .end(\u0026#34;access denied\u0026#34;); } req.user = user; next(); }); } else { return res .status(\u0026#34;401\u0026#34;) .set({ \u0026#34;WWW-Authenticate\u0026#34;: \u0026#39;Basic realm=\u0026#34;Access Denied\u0026#34;\u0026#39; }) .end(\u0026#34;access denied\u0026#34;); } }); Visit basic-auth, ldapauth-fork packages for more information on configuration.\n","date":"2019-05-15T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/node-ldap-auth/","title":"Authenticate a Node application with LDAP"},{"content":"Recently I was faced an issue where one of my project was stuck in terminating state for days. The workaround below fixed the issue.\nExport OpenShift project as an JSON Object\noc get project delete-me -o json \u0026gt; ns-without-finalizers.json Replace below from\nspec:finalizers:- kubernetesto\nspec:finalizers:[]On one of the master node, execute these commands.\nkubectl proxy \u0026amp; PID=$! curl -X PUT http://localhost:8001/api/v1/namespaces/delete-me/finalize \\ -H \u0026#34;Content-Type: application/json\u0026#34; --data-binary @ns-without-finalizers.json kill $PID ","date":"2019-05-15T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/project-terminating/","title":"Deleting a OpenShift project stuck in terminating state"},{"content":"Spring Boot Metrics In this post I\u0026rsquo;ll discuss how to monitor spring boot application metrics using Prometheus and Grafana.\nPrometheus Prometheus is a monitoring system which collects metrics from configured targets at given intervals.\nGrafana Grafana is an open source metric analytics \u0026amp; visualization tool.\nMicrometer Micrometer is a metrics instrumentation library for JVM-based applications.\nSpring Boot Actuator Spring Boot Actuator helps you monitor and manage your application when it’s pushed to production. You can choose to manage and monitor your application using HTTP or JMX endpoints.\nSetup Enable prometheus metrics by adding dependencies in pom.xml\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; By default prometheus endpoint is not available and must be enabled in application.properties. More configurations can be found at spring-boot docs\n#Metrics related configurations management.endpoint.metrics.enabled=true management.endpoints.web.exposure.include=* management.endpoint.prometheus.enabled=true management.metrics.export.prometheus.enabled=true management.metrics.distribution.percentiles-histogram.http.server.requests=true management.metrics.distribution.sla.http.server.requests=1ms,5ms management.metrics.distribution.percentiles.http.server.requests=0.5,0.9,0.95,0.99,0.999 Optionally register any number of MeterRegistryCustomizer to further configure the registry (such as applying common tags) before any meters are registered with the registry.\n@Bean MeterRegistryCustomizer\u0026lt;MeterRegistry\u0026gt; metricsCommonTags() { return registry -\u0026gt; registry.config().commonTags(\u0026#34;application\u0026#34;, \u0026#34;sample-app\u0026#34;); } Create a new project; deploy the application and prometheus in OpenShift.\n$ oc project myproject $ oc new-app redhat-openjdk18-OpenShift~\u0026lt;git_repo_URL\u0026gt; -n sample-app oc new-app prom/prometheus -n prometheus In order to keep the prometheus image and configuration decoupled, use the ConfigMap object to inject our the Prometheus deployment with the appropriate configuration data\ncat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; \u0026gt; prometheus.yml global: scrape_interval: 5s evaluation_interval: 5s scrape_configs: - job_name: \u0026#39;sample-app\u0026#39; metrics_path: \u0026#39;/actuator/prometheus\u0026#39; static_configs: - targets: [\u0026#39;sample-app:8080\u0026#39;] EOF oc create configmap prom-config-example --from-file=prometheus.yml Next, edit the deployment configuration for Prometheus to include this ConfigMap.\noc edit dc/prometheus Add new volume and volume mount\n- name: prom-config-example-volume configMap: name: prom-config-example defaultMode: 420 - name: prom-config-example-volume mountPath: /etc/prometheus/ Use an OpenShift Template to run Grafana with persistent storage.\n$ oc process -f https://gist.githubusercontent.com/Vikaspogu/4a67495acf8dba5dc94837e031129fde/raw/e88f42515c6ed101c9554c7c2425794e80e10a64/OpenShift-grafana.yaml | oc apply -f- Once deployed, log-in to Grafana using the Route provided in the Template and using default account admin with password admin (it maybe a good idea to change the password after this).\nGrafana Data Source   The Grafana template automatically provisions a Prometheus data source App-Prometheus which connects to http://prometheus:9090 via proxy connection.\n  This works only if there is a Prometheus service (called prometheus) in the same project as Grafana. If this is not the case, it is necessary to edit the datasource to point to another location.\n  Grafana Dashboard  The Grafana template automatically provisions sample dashboards. These dashboards are by no means comprehensive but could be used as a starting point for further customization.   grafana-springboot \nYou can find more official \u0026amp; community built grafana dashboards here\n","date":"2019-05-15T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/springboot-metrics-grafana/","title":"Spring Boot metrics with Prometheus and Grafana in OpenShift"},{"content":"This post is about how to remote debug a ASP.NET Core application on OpenShift using Visual Studio Code. You can use any Microsoft proprietary debugger engine vsdbg with Visual Studio Code.\nFirst, list the available .Net application pods using oc command.\n$ oc get pod NAME READY STATUS RESTARTS AGE MY_APP_NAME-3-1xrsp 0/1 Running 0 6s $ oc rsh MY_APP_NAME-3-1xrsp sh-4.2$ curl -sSL https://aka.ms/getvsdbgsh | bash /dev/stdin -v latest -l /opt/app-root/vsdbg -r linux-x64 Note: If you\u0026rsquo;re container is running behind a corporate proxy and cannot access internet, you\u0026rsquo;ll have to build base dotnet image with the debugger engine vsdbg installed in it.\nCreate (or open) the .vscode/launch.json file inside the source directory of the application (i.e. at same level as the project folder), then add the following:\n{ \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;.NET Core OpenShift Pod Remote Attach\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;coreclr\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;processId\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;pipeTransport\u0026#34;: { \u0026#34;pipeProgram\u0026#34;: \u0026#34;oc\u0026#34;, \u0026#34;pipeArgs\u0026#34;: [\u0026#34;exec\u0026#34;, \u0026#34;-it\u0026#34;, \u0026#34;\u0026lt;replace-with-pod-name\u0026gt;\u0026#34;, \u0026#34;--\u0026#34;], \u0026#34;quoteArgs\u0026#34;: false, \u0026#34;debuggerPath\u0026#34;: \u0026#34;/opt/app-root/vsdbg/vsdbg\u0026#34;, \u0026#34;pipeCwd\u0026#34;: \u0026#34;${workspaceRoot}\u0026#34; }, \u0026#34;justMyCode\u0026#34;: false, \u0026#34;sourceFileMap\u0026#34;: { \u0026#34;/opt/app-root/src\u0026#34;: \u0026#34;${workspaceRoot}\u0026#34; } } ] } In Launch.json replace \u0026lt;replace-with-pod-name\u0026gt; with the name of the pod.\nConfirm the PID of the dotnet process in the container. If different, replace the processId in launch.json with appropriate value. Usually this value is 1.\nIf the application is built with the Release configuration, which is the default for .NET Core S2I builder images, justMyCode should be false.\nAs S2I images build the source code located in the /opt/app-root/src folder, this is the path that should be specified for sourceFileMap.\nStart debugging the .NET Core app by switching to the debug window, then select .NET Core OpenShift Pod Remote Attach as the configuration and click on the green play button (as shown below), or press F5 key.\n alt text \nRemember to add the breakpoints in the source code to see debugging in action!\n","date":"2019-05-14T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/debug-netcore-openshift/","title":"Debugging a .NET Core application running on OpenShift"},{"content":"This post will discuss debugging a JAVA application running inside a container.\nRed Hat container images When you bootstrap your JVM, you should have a way to enable JVM debug. For example Red Hat S2I images allows you to control classpath and debugging via environment variables.\n# Set debug options if required if [ x\u0026#34;${JAVA_DEBUG}\u0026#34; != x ] \u0026amp;\u0026amp; [ \u0026#34;${JAVA_DEBUG}\u0026#34; != \u0026#34;false\u0026#34; ]; then java_debug_args=\u0026#34;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=${JAVA_DEBUG_PORT:-5005}\u0026#34; fi  Setting the JAVA_DEBUG environment variable inside the container to true will add debug args to JVM startup command Configure port forwarding so that you can connect to your application from a remote debugger   If you are using tomcat image replace JAVA_DEBUG environment variable to DEBUG\n Using the oc command, list the available deployment configurations:\noc get dc Enable Debug Set the JAVA_DEBUG environment variable in the deployment configuration of your application to true, which configures the JVM to open the port number 5005 for debugging.\noc set env dc/MY_APP_NAME JAVA_DEBUG=true  Disabling the health checks is not mandatory but it is recommended because a pod could be restarted while the process is paused during remote debugging. You can remove the readiness check to prevent an unintended restart.\n Redeploy Redeploy the application if it is not set to redeploy automatically on configuration change.\noc rollout latest dc/MY_APP_NAME Configure port forwarding from your local machine to the application pod. List the currently running pods and find one containing your application. $LOCAL_PORT_NUMBER is an unused port number of your choice on your local machine. Remember this number for the remote debugger configuration.\n If you are using tomcat image replace the port 5005 to 8000\n oc get pod NAME READY STATUS RESTARTS AGE MY_APP_NAME-3-1xrsp 1/1 Running 0 6s ... oc port-forward MY_APP_NAME-3-1xrsp $LOCAL_PORT_NUMBER:5005 IntelliJ Config Create a new debug configuration for your application in IntelliJ IDE:\n  Click Run → Edit Configurations\n  In the list of configurations, add Remote. This creates a new remote debugging configuration\n  Enter a suitable name for the configuration in the name field\n  Set the port field to the port number that your application is listening on for debugging\n  Click Apply\n intellij-debug \n  Click Run -\u0026gt; Debug -\u0026gt; Select Profile\n Debugger connected \n  When you are done debugging, unset the JAVA_DEBUG environment variable in your application pod.\noc set env dc/MY_APP_NAME JAVA_DEBUG- Non Red Hat container images If you are using openjdk image to build application, update ENTRYPOINT as below to pass options to the JVM through $JAVA_OPTS environment variable\nFROMopenjdk:11.0.3-jdk-slimRUN mkdir /usr/myappCOPY target/java-kubernetes.jar /usr/myapp/app.jarWORKDIR/usr/myappEXPOSE8080ENTRYPOINT [ \u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;java $JAVA_OPTS -jar app.jar\u0026#34; ]And then set deployments JAVA_OPTS environment variable\noc set env deployment MY_APP_NAME JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,address=*:5005,server=y,suspend=n ","date":"2019-05-14T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/debug-java-container/","title":"Debugging a Java application in OpenShift"},{"content":"Sometimes writing code that just runs is not enough. We might want to know what goes on internally such as how memory is allocated, consequences of using one coding approach over another, implications of concurrent executions, areas to improve performance, etc. We can use profilers for this.\nIn this post I\u0026rsquo;ll discuss how to use YourKit-JavaProfiler inside a container.\nSince my sample application is built using OpenShift S2I process and pushed into OpenShift internal registry, I\u0026rsquo;ll have to pull the image locally.\ndocker login -p $(oc whoami --show-token) -u admin docker-registry.example.com docker pull docker-registry.example.com/myproject/sample-app:latest Create a new Dockerfile, add few lines to install YourKit Java Profiler agents and expose the profiler agent port.\nFROMdocker-registry.example.com/myproject/sample-app:latestRUN wget https://www.yourkit.com/download/docker/YourKit-JavaProfiler-2019.1-docker.zip -P /tmp/ \u0026amp;\u0026amp; \\  unzip /tmp/YourKit-JavaProfiler-2019.1-docker.zip -d /usr/local \u0026amp;\u0026amp; \\  rm /tmp/YourKit-JavaProfiler-2019.1-docker.zipEXPOSE10001Build and push the image into registry\ndocker build . -t docker-registry.example.com/myproject/sample-app-profiler:latest docker push docker-registry.example.com/myproject/sample-app-profiler:latest Update image in the deployment configuration.\n profiler-image \nLoad the agent into the JVM by adding a JAVA_TOOL_OPTIONS environment variable in the deployment configuration.\n$ oc set env dc/MY_APP_NAME JAVA_TOOL_OPTIONS=-agentpath:/usr/local/YourKit-JavaProfiler-2019.01/bin/linux-x86-64/libyjpagent.so=port=10001,listen=all oc rollout latest dc/MY_APP_NAME Once deployment is finished, do a oc port forwarding from your local machine to the application pod.\n$ oc get pod NAME READY STATUS RESTARTS AGE MY_APP_NAME-3-1xrsp 1/1 Running 0 6s ... $ oc port-forward MY_APP_NAME-3-1xrsp 10001:10001 Add a connection in the profiler with localhost:10001 and you\u0026rsquo;re all set.\n","date":"2019-05-14T00:00:00Z","permalink":"https://vikaspogu.github.io/posts/javaprofiler-openshift/","title":"Profiling a application in OpenShift container"}]